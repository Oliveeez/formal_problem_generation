{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96c531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import json\n",
    "import collections as C\n",
    "import itertools as I\n",
    "import random\n",
    "import regex as re\n",
    "import multiprocessing as mp\n",
    "import dataclasses as D\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from dacite import from_dict\n",
    "from loguru import logger\n",
    "\n",
    "from common.constants import BANNED_TOKENS_IN_ANSWER_TYPE, BANNED_TOKENS_IN_SOLVING_STATE, CORE_OPTIONS, FPS_GLOBAL_SETTING, OPEN_HEADER\n",
    "from common.pantograph.dataclasses import Goal, GoalState, Variable, CompilationUnit, TacticDraft, FormalProblem, SolutionAutoformalizationResult\n",
    "from common.pantograph.server import Server, TacticFailure\n",
    "from common.pantograph.solving_server import PersistentPropSolvingServer\n",
    "from common.utils import remove_comments, normalize_spaces, format_forward_solution_step_prompt, replace_span, chunk_list, parse_idents, remove_min_whitespace\n",
    "\n",
    "\n",
    "@D.dataclass(frozen=True)\n",
    "class ProblemGenerationStep:\n",
    "    step_draft: str\n",
    "    proof: Optional[Tuple[str]]\n",
    "    new_contexts: Optional[Tuple[Variable]] # Newly introduced contexts (excluding removed old contexts, including newly-modified contexts)\n",
    "\n",
    "    def __post__init__(self):\n",
    "        self.proof = tuple(self.proof)\n",
    "        self.new_contexts = tuple(self.new_contexts)\n",
    "\n",
    "    @property\n",
    "    def is_introducing(self):\n",
    "        return self.proof is None\n",
    "    \n",
    "    @property\n",
    "    def is_deducing(self):\n",
    "        return not self.is_introducing and not self.is_submitting\n",
    "\n",
    "    @property\n",
    "    def is_submitting(self):\n",
    "        return self.new_contexts is None\n",
    "    \n",
    "    @property\n",
    "    def step(self):\n",
    "        if self.proof is None:\n",
    "            return self.step_draft\n",
    "        else:\n",
    "            normalized_step_draft = normalize_draft(self.step_draft)\n",
    "            matches = list(re.finditer(':= sorry', normalized_step_draft))\n",
    "            assert len(matches) == len(self.proof)\n",
    "            for (m, p) in reversed(list(zip(matches, self.proof))):\n",
    "                normalized_step_draft = replace_span(m.span(), ':= by {\\n' + p + '\\n}', normalized_step_draft)\n",
    "            return normalized_step_draft\n",
    "\n",
    "\n",
    "def normalize_draft(s: str) -> str:\n",
    "    s_normalized = re.sub(\n",
    "        r':=\\s*sorry', r':= sorry',\n",
    "            re.sub(\n",
    "        r':=\\s*by\\s+sorry', r':= sorry',\n",
    "        remove_comments(s)\n",
    "    )).strip()\n",
    "    s_filled = re.sub(r'have\\s+:', r'have this :', s_normalized)\n",
    "    return '\\n'.join(l for l in s_filled.splitlines() if l.strip() != '')\n",
    "\n",
    "\n",
    "FPS_GLOBAL_SETTING['TO_SYNC_ENABLED'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b3b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = PersistentPropSolvingServer(\n",
    "    imports=[\"Mathlib\", \"Aesop\"],\n",
    "    project_path='/home/ma-user/workspace/formal_problem_generation/formal_problem_generation/data/MiniF2F',\n",
    "    timeout=120,\n",
    "    _sync_init=False,\n",
    ")\n",
    "\n",
    "server.set_tag(f'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee1a29",
   "metadata": {},
   "source": [
    "## Load from CoPA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d15b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_cycle1(args):\n",
    "    path = args\n",
    "    with open(osp.join(path), 'rb') as f:\n",
    "        _, _, _, _, data = pickle.load(f)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc48352a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n"
     ]
    }
   ],
   "source": [
    "# Cycle 1\n",
    "data_root = '/sfs/liuqi/data/AI-MO/NuminaMath-1.5/cycle2/dones_all'\n",
    "\n",
    "ps = [osp.join(data_root, p) for p in os.listdir(data_root) if p.startswith('processed_') and p.endswith('.pkl')]\n",
    "print(len(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc06064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mp.Pool(processes=128) as pool:\n",
    "#     results = pool.map(worker_cycle1, ps)\n",
    "samples = [worker_cycle1(ps[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691b6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(I.chain(*samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c0dbb",
   "metadata": {},
   "source": [
    "## Load from Kangjie Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ddc1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/MiniF2F/example_deductive_proof.lean', 'r') as f:\n",
    "    examples = f.read().split('example\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5da24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = []\n",
    "\n",
    "# for (i, ex) in examples:\n",
    "#     elems = ex.split('\\n\\n')\n",
    "#     assert elems[0].endswith(':= by')\n",
    "#     formal_statement = 'example\\n' + elems[0][:-len(':= by')] + ':= sorry'\n",
    "#     solution_steps = [\n",
    "#         remove_min_whitespace(e) for e in elems[1:] if len(remove_comments(e).strip()) > 0\n",
    "#     ]\n",
    "#     assert solution_steps[-1] == 'exact h_answer'\n",
    "#     sample = await server.load_problem_async(SolutionAutoformalizationResult(\n",
    "#         header=OPEN_HEADER,\n",
    "#         formal_statement=formal_statement\n",
    "#     ))\n",
    "#     sample.metainfo['solution_state_transition'] = [(None, s) for s in solution_steps]\n",
    "#     samples.append(\n",
    "#         sample\n",
    "#     )\n",
    "#     print(f'{i}/{len(examples)}')\n",
    "#     print(formal_statement)\n",
    "\n",
    "# with open('data/MiniF2F/example_deductive_proof.pkl', 'wb') as f:\n",
    "#     pickle.dump(samples, f)\n",
    "\n",
    "with open('data/MiniF2F/example_deductive_proof.pkl', 'rb') as f:\n",
    "    samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91626e2f",
   "metadata": {},
   "source": [
    "## Choose Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648c0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example\n",
      "  -- s is the index set {1,2,..., 999}\n",
      "  (s : Finset ℤ)\n",
      "  (hs : s = Finset.Icc 1 999)\n",
      "  -- a and b are two sequence\n",
      "  (a b : ℤ → ℤ)\n",
      "  -- the set {1,2, ..., 1998} has been partitioned into disjoint pairs {a_i, b_i} (1 ≤ i ≤ 999)\n",
      "  (ha : ∀ i ∈ s, a i ∈ Finset.Icc 1 1998)\n",
      "  (hb : ∀ i ∈ s, b i ∈ Finset.Icc 1 1998)\n",
      "  (hij : ∀ i ∈ s, ∀ j ∈ s, i ≠ j → a i ≠ a j ∧ b i ≠ b j)\n",
      "  (hij' : ∀ i ∈ s, ∀ j ∈ s, a i ≠ b j)\n",
      "  -- |a_i - b_i| equals 1 or 6\n",
      "  (habs : ∀ i ∈ s, |a i - b i| = 1 ∨ |a i - b i| = 6)\n",
      "  -- Find that the sum |a_1 - b_1| + |a_2 - b_2| + ... + |a_999 - b_999| ends in which digit\n",
      "  (answer : ℤ)\n",
      "  (h_answer : answer = (∑ i ∈ s, |a i - b i|) % 10)\n",
      "  -- # Answer 9\n",
      "  : answer = 9\n",
      ":= sorry\n"
     ]
    }
   ],
   "source": [
    "sample = samples[-1]\n",
    "\n",
    "solution_transitions = sample.metainfo['solution_state_transition'][:]\n",
    "formal_proofs = sample.formal_proofs[:]\n",
    "\n",
    "print(sample.formal_statement)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08f7b4",
   "metadata": {},
   "source": [
    "## Dependency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3eeb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_answer\n"
     ]
    }
   ],
   "source": [
    "state, action = solution_transitions[-1]\n",
    "action = remove_comments(action).strip()\n",
    "assert action.startswith('exact ')\n",
    "submission_name = action[len('exact '):]\n",
    "print(submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2248e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-29 16:44:45.265\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcommon.pantograph.server\u001b[0m:\u001b[36mcheck_restart_async\u001b[0m:\u001b[36m565\u001b[0m - \u001b[34m\u001b[1mPersistentServer(test/tactic_server): Restarting...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "forward_state = await server.init_forward_reasoning_state_async(sample)\n",
    "assert len(forward_state.goals) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9f894b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all('✝' not in v.name for v in forward_state.goals[0].variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdc2d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_draft_normalized = normalize_draft('\\n'.join([s[1] for s in solution_transitions]))\n",
    "matches = list(re.finditer(':= sorry', solution_draft_normalized))\n",
    "assert len(matches) == len(formal_proofs), f'`len(matches) == len(formal_proofs)` failed because {len(matches)} != {len(formal_proofs)}, unable to prune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514cf99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_graph = nx.DiGraph()\n",
    "hard_dependencies_global = []\n",
    "parsed_steps = [\n",
    "    ProblemGenerationStep(\n",
    "        step_draft=f'have {v.name} : {v.t} := sorry' if v.v is None else f'let {v.name} : {v.t} := {v.v}',\n",
    "        proof=None,\n",
    "        new_contexts=tuple([v])\n",
    "    ) for v in forward_state.goals[0].variables\n",
    "]\n",
    "fvarid_to_istep = {\n",
    "    v.raw_name : i for (i, v) in enumerate(forward_state.goals[0].variables)\n",
    "}\n",
    "i_proof = 0\n",
    "\n",
    "\n",
    "# Add dependencies between current `parsed_steps` (hypotheses)\n",
    "dependency_graph.add_nodes_from(parsed_steps)\n",
    "for (i, v) in enumerate(parsed_steps):\n",
    "    idents = parse_idents(v.new_contexts[0].t)\n",
    "    for u in parsed_steps[:i]:\n",
    "        if u.new_contexts[0].name in idents:\n",
    "            # edge (u, v): v depends on u\n",
    "            dependency_graph.add_edge(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a2c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-29 16:47:21.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mStep: have heq : ∀ i ∈ s, |a i - b i| % 2 = (a i + b i) % 2 := by\n",
      "  intro x hx\n",
      "  by_cases hge : a x ≥ b x\n",
      "  · have this : |a x - b x| = a x - b x := by\n",
      "      rw [@abs_eq_self]\n",
      "      linarith\n",
      "    rw [this]\n",
      "    apply Int.modEq_iff_dvd.mpr\n",
      "    ring_nf\n",
      "    exact Int.dvd_mul_left (b x) 2\n",
      "  · have this : |a x - b x| = - (a x - b x) := by\n",
      "      rw [@abs_eq_neg_self]\n",
      "      linarith\n",
      "    rw [this]\n",
      "    apply Int.modEq_iff_dvd.mpr\n",
      "    ring_nf\n",
      "    exact Int.dvd_mul_left (a x) 2\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:22.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove s : Finset ℤ (['s'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:22.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hs : s = Finset.Icc 1 999 (['hs'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:22.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove a : ℤ → ℤ (['a'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:22.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove b : ℤ → ℤ (['b'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:23.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved ha : ∀ i ∈ s, a i ∈ Finset.Icc 1 1998 (['ha'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:23.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hb : ∀ i ∈ s, b i ∈ Finset.Icc 1 1998 (['hb'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:24.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hij : ∀ i ∈ s, ∀ j ∈ s, i ≠ j → a i ≠ a j ∧ b i ≠ b j (['hij'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:24.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hij' : ∀ i ∈ s, ∀ j ∈ s, a i ≠ b j ([\"hij'\"])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:24.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved habs : ∀ i ∈ s, |a i - b i| = 1 ∨ |a i - b i| = 6 (['habs'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:24.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove answer : ℤ (['answer'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:25.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved h_answer : answer = (∑ i ∈ s, |a i - b i|) % 10 (['h_answer'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:25.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mFinal removing state: s : Finset ℤ\n",
      "a b : ℤ → ℤ\n",
      "answer : ℤ\n",
      "heq : ∀ i ∈ s, |a i - b i| % 2 = (a i + b i) % 2\n",
      "⊢ False\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:25.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['b'] -> ['heq']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:25.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['a'] -> ['heq']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:25.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['s'] -> ['heq']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:25.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['answer'] -> ['heq']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:25.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mStep: have heqsum : (∑ i ∈ s, |a i - b i|) % 2 = (∑ i ∈ s, (a i + b i)) % 2 := by\n",
      "  rw [Finset.sum_int_mod]\n",
      "  nth_rw 2 [Finset.sum_int_mod]\n",
      "  rw [Finset.sum_congr rfl heq]\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:26.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove s : Finset ℤ (['s'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:26.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hs : s = Finset.Icc 1 999 (['hs'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:26.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove a : ℤ → ℤ (['a'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:26.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove b : ℤ → ℤ (['b'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:26.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved ha : ∀ i ∈ s, a i ∈ Finset.Icc 1 1998 (['ha'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:26.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hb : ∀ i ∈ s, b i ∈ Finset.Icc 1 1998 (['hb'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:26.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hij : ∀ i ∈ s, ∀ j ∈ s, i ≠ j → a i ≠ a j ∧ b i ≠ b j (['hij'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved hij' : ∀ i ∈ s, ∀ j ∈ s, a i ≠ b j ([\"hij'\"])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved habs : ∀ i ∈ s, |a i - b i| = 1 ∨ |a i - b i| = 6 (['habs'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mCannot remove answer : ℤ (['answer'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mRemoved h_answer : answer = (∑ i ∈ s, |a i - b i|) % 10 (['h_answer'])\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1m['heqsum'] depends on ['heq']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mFinal removing state: s : Finset ℤ\n",
      "a b : ℤ → ℤ\n",
      "answer : ℤ\n",
      "heq : ∀ i ∈ s, |a i - b i| % 2 = (a i + b i) % 2\n",
      "heqsum : (∑ i ∈ s, |a i - b i|) % 2 = (∑ i ∈ s, (a i + b i)) % 2\n",
      "⊢ False\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['b'] -> ['heqsum']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['a'] -> ['heqsum']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['s'] -> ['heqsum']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['answer'] -> ['heqsum']\u001b[0m\n",
      "\u001b[32m2025-07-29 16:47:27.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mAdding dependency: ['heq'] -> ['heqsum']\u001b[0m\n"
     ]
    },
    {
     "ename": "TacticFailure",
     "evalue": "{'tacticErrors': ['<Pantograph>:0:2437: error: auxiliary declaration cannot be created when declaration name is not available\\n']}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTacticFailure\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m     new_forward_state = \u001b[38;5;28;01mawait\u001b[39;00m server.tactic_server.goal_tactic_async(forward_state, \u001b[32m0\u001b[39m, TacticDraft(\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + normalized_draft_step + \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33msorry\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     new_forward_state = \u001b[38;5;28;01mawait\u001b[39;00m server.tactic_server.goal_tactic_async(forward_state, \u001b[32m0\u001b[39m, normalized_draft_step)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m new_forward_state.goals[-\u001b[32m1\u001b[39m].target == \u001b[33m'\u001b[39m\u001b[33mFalse\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m n_sorries = \u001b[38;5;28mlen\u001b[39m(new_forward_state.goals) - \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cache/workspace/formal_problem_generation/formal_problem_generation/common/pantograph/server.py:540\u001b[39m, in \u001b[36mrecord_server_error.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    541\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (ServerError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m, pexpect.exceptions.TIMEOUT) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cache/workspace/formal_problem_generation/formal_problem_generation/common/pantograph/server.py:623\u001b[39m, in \u001b[36mPersistentServer.goal_tactic_async\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;129m@record_server_error\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgoal_tactic_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> GoalState:\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_state_based, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPersistentServer(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): goal_tactic_async() must be used w/ state-based.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.server.goal_tactic_async(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cache/workspace/formal_problem_generation/formal_problem_generation/common/pantograph/server.py:322\u001b[39m, in \u001b[36mServer.goal_tactic_async\u001b[39m\u001b[34m(self, state, goal_id, tactic)\u001b[39m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServerError(result)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtacticErrors\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TacticFailure(result)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mparseError\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TacticFailure(result)\n",
      "\u001b[31mTacticFailure\u001b[39m: {'tacticErrors': ['<Pantograph>:0:2437: error: auxiliary declaration cannot be created when declaration name is not available\\n']}"
     ]
    }
   ],
   "source": [
    "for i_step, (_, draft_step) in enumerate(solution_transitions[:-1]):\n",
    "    # 1. Execute current step\n",
    "    normalized_draft_step = normalize_draft(draft_step)\n",
    "    if 'sorry' in parse_idents(normalized_draft_step):\n",
    "        new_forward_state = await server.tactic_server.goal_tactic_async(forward_state, 0, TacticDraft('by\\n' + normalized_draft_step + '\\nsorry'))\n",
    "    else:\n",
    "        new_forward_state = await server.tactic_server.goal_tactic_async(forward_state, 0, normalized_draft_step)\n",
    "\n",
    "    assert new_forward_state.goals[-1].target == 'False'\n",
    "    n_sorries = len(new_forward_state.goals) - 1\n",
    "    for p in sample.formal_proofs[i_proof:i_proof+n_sorries]:\n",
    "        new_forward_state = await server.tactic_server.goal_tactic_async(new_forward_state, 0, '{\\n' + '\\n'.join([remove_min_whitespace(s[1]) for s in p.proof]) + '\\n}')\n",
    "    \n",
    "    assert len(new_forward_state.goals) == 1 and new_forward_state.goals[0].target == 'False'\n",
    "    \n",
    "    # 2. Analyze state difference\n",
    "    new_contexts = [\n",
    "        v for v in new_forward_state.goals[0].variables if\n",
    "            v.raw_name not in {vv.raw_name for vv in forward_state.goals[0].variables}\n",
    "            # v not in forward_state.goals[0].variables\n",
    "    ]\n",
    "    if len(new_contexts) == 0:\n",
    "        logger.warning(f'Unused step: {[normalized_draft_step]}')\n",
    "    for v in new_contexts:\n",
    "        # assert v.raw_name not in fvarid_to_istep.keys()\n",
    "        fvarid_to_istep[v.raw_name] = len(parsed_steps) # Maybe override!\n",
    "    \n",
    "    # 3.1 Add parsed step\n",
    "    cur_step = ProblemGenerationStep(\n",
    "        step_draft=draft_step,\n",
    "        proof=tuple(['\\n'.join([remove_min_whitespace(s[1]) for s in p.proof]) for p in sample.formal_proofs[i_proof:i_proof+n_sorries]]),\n",
    "        new_contexts=tuple(new_contexts)\n",
    "    )\n",
    "    logger.info(f'Step: {cur_step.step}')\n",
    "    parsed_steps.append(cur_step)\n",
    "    dependency_graph.add_node(cur_step)\n",
    "    i_proof += n_sorries\n",
    "    # 3.2 Coarse-grained dependency\n",
    "    # - Case 1. types in new_contexts\n",
    "    # - Case 2. proofs\n",
    "    \n",
    "    # 4. (Optional) Validate assumption: forward_state.goals[0].variables is topologically sorted\n",
    "    tmp_parsing_state = forward_state\n",
    "    while len(tmp_parsing_state.goals[0].variables) > 0:\n",
    "        tmp_parsing_state = await server.tactic_server.goal_tactic_async(tmp_parsing_state, 0, f'clear {tmp_parsing_state.goals[0].variables[-1].name}')\n",
    "    assert str(tmp_parsing_state) == '⊢ False'\n",
    "    \n",
    "    # 5. Analyze dependency\n",
    "    soft_dependencies = set()    # Set of fVarId. Removing which will corrupt other variables\n",
    "    hard_dependencies = set()    # Set of fVarId. Removing which will make the current step unable to prove\n",
    "    # Try removing `v` and re-executing cur_step\n",
    "    # Assumption: tmp_parsing_state.goals[0].variables is topologically sorted\n",
    "    tmp_parsing_state = forward_state\n",
    "    \n",
    "    for v in forward_state.goals[0].variables:  # TODO: Debug, removed 'reversed'\n",
    "        assert v.raw_name not in soft_dependencies and v.raw_name not in hard_dependencies\n",
    "        \n",
    "        # Shall we try clearing steps introducing `v` and all variables dependent on it?\n",
    "        # No. Because this clearing is in reversed order. If some variable `u` is dependent on `v`\n",
    "        # - Case 1. `s` does not depend on `u`: `u` is already removed\n",
    "        # - Case 2. `s` depends on `u`: it does not matter if we still connect `v` with `u`.\n",
    "        # TODO: Maybe add an extra edge pruning to remove all non-direct dependencies? (i.e. dependencies that can be constructed by transitive dependency)\n",
    "\n",
    "        # 5.1. Find v\n",
    "        v_to_remove = [vv for vv in tmp_parsing_state.goals[0].variables if vv.raw_name == v.raw_name]\n",
    "        assert len(v_to_remove) == 1    # `tmp_parsing_state` is constructed by iteratively removing variables in forward_state, thus must find exactly one\n",
    "        v_to_remove = v_to_remove[0]\n",
    "        \n",
    "        # 5.1. Try removing `v`\n",
    "        if '✝' not in v.name:\n",
    "            try:\n",
    "                new_tmp_parsing_state = await server.tactic_server.goal_tactic_async(tmp_parsing_state, 0, f'clear {v.name}')\n",
    "            except TacticFailure:\n",
    "                soft_dependencies.add(v.raw_name)\n",
    "                logger.info(f'Cannot remove {v} ({[vv.name for vv in parsed_steps[fvarid_to_istep[v.raw_name]].new_contexts]})')\n",
    "                continue\n",
    "        else:\n",
    "            n_inaccessible_after = 0\n",
    "            for vv in reversed(tmp_parsing_state.goals[0].variables):\n",
    "                if vv.raw_name == v.raw_name:\n",
    "                    break\n",
    "                else:\n",
    "                    if '✝' in vv.name:\n",
    "                        n_inaccessible_after += 1\n",
    "            assert all(vv.name != '_TMP_NAME_TO_REMOVE' for vv in tmp_parsing_state.goals[0].variables)\n",
    "            new_tmp_parsing_state = await server.tactic_server.goal_tactic_async(tmp_parsing_state, 0, f'rename_i _TMP_NAME_TO_REMOVE' + ' _' * n_inaccessible_after)\n",
    "            \n",
    "            all_to_temove = [vv for vv in new_tmp_parsing_state.goals[0].variables if vv.name == '_TMP_NAME_TO_REMOVE']\n",
    "            assert len(all_to_temove) == 1 and all_to_temove[0].raw_name == v_to_remove.raw_name\n",
    "            \n",
    "            try:\n",
    "                new_tmp_parsing_state = await server.tactic_server.goal_tactic_async(tmp_parsing_state, 0, f'clear _TMP_NAME_TO_REMOVE')\n",
    "            except TacticFailure:\n",
    "                soft_dependencies.add(v.raw_name)\n",
    "                logger.info(f'Cannot remove {v} ({[vv.name for vv in parsed_steps[fvarid_to_istep[v.raw_name]].new_contexts]})')\n",
    "                continue\n",
    "        \n",
    "        # Step 2. Try executing cur_step\n",
    "        try:\n",
    "            test_tmp_parsing_state = await server.tactic_server.goal_tactic_async(new_tmp_parsing_state, 0, cur_step.step)\n",
    "            tmp_parsing_state = new_tmp_parsing_state\n",
    "        except TacticFailure:\n",
    "            hard_dependencies.add(v.raw_name)\n",
    "            hard_dependencies_global.append((parsed_steps[fvarid_to_istep[v.raw_name]], cur_step))\n",
    "            logger.info(f'{[vv.name for vv in cur_step.new_contexts]} depends on {[vv.name for vv in parsed_steps[fvarid_to_istep[v.raw_name]].new_contexts]}')\n",
    "            continue\n",
    "        logger.info(f'Removed {v} ({[vv.name for vv in parsed_steps[fvarid_to_istep[v.raw_name]].new_contexts]})')\n",
    "    logger.info(f'Final removing state: {test_tmp_parsing_state}')\n",
    "    # 6. Iteration end\n",
    "    for d in I.chain(soft_dependencies, hard_dependencies):\n",
    "        # edge (u, v): v depends on u\n",
    "        logger.info(f'Adding dependency: {[vv.name for vv in parsed_steps[fvarid_to_istep[d]].new_contexts]} -> {[vv.name for vv in cur_step.new_contexts]}')\n",
    "        dependency_graph.add_edge(parsed_steps[fvarid_to_istep[d]], cur_step)\n",
    "    \n",
    "    forward_state = new_forward_state\n",
    "\n",
    "assert i_proof == len(formal_proofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ef0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert submission_name in [v.name for v in parsed_steps[-1].new_contexts]\n",
    "\n",
    "submission_step = ProblemGenerationStep(\n",
    "    step_draft=f'submit_answer {submission_name}',\n",
    "    proof=None,\n",
    "    new_contexts=None\n",
    ")\n",
    "dependency_graph.add_node(submission_step)\n",
    "for s in reversed(parsed_steps):\n",
    "    if submission_name in [v.name for v in s.new_contexts]:\n",
    "        dependency_graph.add_edge(s, submission_step)\n",
    "        break\n",
    "assert dependency_graph.in_degree(submission_step) == 1\n",
    "parsed_steps.append(submission_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a27e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in parsed_steps:\n",
    "    print(normalize_draft(step.step))\n",
    "    print('\\n'.join(v.raw_name + ' ' + str(v) for v in (step.new_contexts or [])))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dependency_graph.nodes), len(parsed_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa967f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dependency_graph = nx.algorithms.dag.transitive_reduction(dependency_graph)\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(reduced_dependency_graph, prog=\"dot\", args=\"\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# pos = nx.bfs_layout(dependency_graph, parsed_steps[0])\n",
    "# pos = forest_bfs_layout(dependency_graph, [node for node, in_degree in dependency_graph.in_degree() if in_degree == 0])\n",
    "\n",
    "color_map = ['orange' if node.is_submitting else 'cyan' if node.is_deducing else 'green' for node in reduced_dependency_graph.nodes]\n",
    "# edge_styles = [\n",
    "#     ('--' if e not in hard_dependencies_global else '-') for e in reduced_dependency_graph.edges\n",
    "# ]\n",
    "\n",
    "labels = {node: '\\n'.join(str(v) for v in (node.new_contexts or [node.step])) for node in reduced_dependency_graph}\n",
    "\n",
    "nx.draw(reduced_dependency_graph, pos, with_labels=True, labels=labels, node_size=800, font_size=6, node_color=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#* For visualization only\n",
    "direct_dependency_graph = nx.algorithms.dag.transitive_reduction(dependency_graph)\n",
    "direct_dependency_graph.add_edges_from(hard_dependencies_global) # Add this -> direct dependency graph\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(direct_dependency_graph, prog=\"dot\", args=\"\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# pos = nx.bfs_layout(dependency_graph, parsed_steps[0])\n",
    "# pos = forest_bfs_layout(dependency_graph, [node for node, in_degree in dependency_graph.in_degree() if in_degree == 0])\n",
    "\n",
    "color_map = ['orange' if node.is_submitting else 'cyan' if node.is_deducing else 'green' for node in reduced_dependency_graph.nodes]\n",
    "# edge_styles = [\n",
    "#     ('--' if e not in hard_dependencies_global else '-') for e in reduced_dependency_graph.edges\n",
    "# ]\n",
    "\n",
    "labels = {node: '\\n'.join(str(v) for v in (node.new_contexts or [node.step])) for node in direct_dependency_graph}\n",
    "\n",
    "nx.draw(direct_dependency_graph, pos, with_labels=True, labels=labels, node_size=800, font_size=6, node_color=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe52a79c",
   "metadata": {},
   "source": [
    "## Exploratory Action Sequence Reassembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14042250",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_dict = {n : 0 for n in parsed_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in nx.topological_sort(reduced_dependency_graph):\n",
    "    for v in reduced_dependency_graph.successors(u):\n",
    "        depth_dict[v] = max(depth_dict[v], depth_dict[u]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.nx_agraph.graphviz_layout(reduced_dependency_graph, prog=\"dot\", args=\"\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "color_map = ['orange' if node.is_submitting else 'cyan' if node.is_deducing else 'green' for node in reduced_dependency_graph.nodes]\n",
    "\n",
    "labels = {n: str(depth_dict[n]) + '\\n' + '\\n'.join(str(v) for v in (n.new_contexts or [n.step])) for n in reduced_dependency_graph.nodes}\n",
    "\n",
    "nx.draw(reduced_dependency_graph, pos, with_labels=True, labels=labels, node_size=800, font_size=6, node_color=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reassembled_trajectory = []\n",
    "G = reduced_dependency_graph.copy()\n",
    "deductive_state = await server.tactic_server.load_statement_async('False')\n",
    "\n",
    "while True:\n",
    "    available_actions = sorted([n for (n, d) in G.in_degree() if d == 0], key=lambda n : (-depth_dict[n], n.is_introducing))\n",
    "    chosen_action = available_actions[0]\n",
    "    reassembled_trajectory.append((deductive_state.goals[0].variables, chosen_action))\n",
    "    if chosen_action.is_submitting:\n",
    "        assert submission_name in [v.name for v in deductive_state.goals[0].variables]\n",
    "        if not set(deductive_state.goals[0].variables).issubset(set(forward_state.goals[0].variables)):\n",
    "            logger.warning(f'¬(deductive_state ⊆ forward_state): {deductive_state.goals[0].variables}, {forward_state.goals[0].variables}')\n",
    "        break\n",
    "    deductive_state = await server.tactic_server.goal_tactic_async(forward_state, 0, chosen_action.step)\n",
    "    G.remove_node(chosen_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee99cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.nx_agraph.graphviz_layout(reduced_dependency_graph, prog=\"dot\", args=\"\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "color_map = ['orange' if node.is_submitting else 'cyan' if node.is_deducing else 'green' for node in reduced_dependency_graph.nodes]\n",
    "\n",
    "order_dict = {\n",
    "    n : i for i, (s, n) in enumerate(reassembled_trajectory)\n",
    "}\n",
    "labels = {n: f'{order_dict[n]}, {depth_dict[n]}' + '\\n' + '\\n'.join(str(v) for v in (n.new_contexts or [n.step])) for n in reduced_dependency_graph.nodes}\n",
    "\n",
    "nx.draw(reduced_dependency_graph, pos, with_labels=True, labels=labels, node_size=800, font_size=6, node_color=color_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e288512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
