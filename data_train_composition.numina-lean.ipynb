{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fb9cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/nnae/latest owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/nnae/8.2.RC1/ascend_nnae_install.info owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/__init__.py:289: UserWarning: On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default.                      Do not set it to 1 to prevent some unknown errors\n",
      "  warnings.warn(\"On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default. \\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import pickle\n",
    "import collections as C\n",
    "import itertools as I\n",
    "import random\n",
    "import regex as re\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "import time\n",
    "\n",
    "import msgspec\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from dacite import from_dict\n",
    "import dacite\n",
    "\n",
    "from common.constants import SYSTEM_PROMPT_FPG, CORE_OPTIONS, BANNED_TOKENS\n",
    "from common.utils import remove_comments, replace_sorry, replace_calc, remove_multiline_comments, remove_singleline_comments, parse_idents\n",
    "from common.pantograph.dataclasses import ProblemGenerationProcess, ProblemGenerationStep, Variable, normalize_draft, replace_span, Goal, GoalState, ProblemGenerationStep, ProblemGenerationProcess, TacticDraft\n",
    "from common.pantograph.server import PersistentServer, TacticFailure, ServerError\n",
    "from agent.problem_generation import AutoregressiveProblemGenerationAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e219d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_xtuner_sample(data: list):\n",
    "    if 'system' in data['conversation'][0].keys():\n",
    "        print('<SYSTEM>')\n",
    "        print(data['conversation'][0]['system'])\n",
    "        print('</SYSTEM>')\n",
    "    print('<INPUT>')\n",
    "    print(data['conversation'][0]['input'])\n",
    "    print('</INPUT>\\n<OUTPUT>')\n",
    "    print(data['conversation'][0]['output'])\n",
    "    print('</OUTPUT>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5c7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:32<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/deductive_transformation'\n",
    "data = []\n",
    "\n",
    "for i in tqdm(list(range(41))):\n",
    "    with open(osp.join(base_dir, f'done_v2_chunk_{1024*i}.pkl'), 'rb') as f:\n",
    "        data.extend(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f60b4",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5441a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41109 39840 1269\n"
     ]
    }
   ],
   "source": [
    "data_parsed = [d for d in data if d is not None]\n",
    "assert all('parse_result' in d.keys() for d in data_parsed)\n",
    "print(len(data), len(data_parsed), len(data)-len(data_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db80f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41543 40069 1474\n"
     ]
    }
   ],
   "source": [
    "n_total_units = 0\n",
    "n_transformed_units = 0\n",
    "for d in data_parsed:\n",
    "    units = d['parse_result']['units']\n",
    "    all_parsed_units = [i_u for i_u, u in enumerate(units) if len(u['invocations'] or []) > 0]\n",
    "    n_total_units += len(all_parsed_units)\n",
    "    n_transformed_units += len([i_u for i_u in all_parsed_units if 'deductive_steps' in units[i_u].keys()])\n",
    "print(n_total_units, n_transformed_units, n_total_units-n_transformed_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b062f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eq.symm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m submission \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m submission:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(submission)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     20\u001b[39m     submission_cnt[submission] += \u001b[32m1\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "anonymous_name_cnt = C.Counter()\n",
    "submission_cnt = C.Counter()\n",
    "\n",
    "for d in data_parsed:\n",
    "    for u in d['parse_result']['units']:\n",
    "        if 'deductive_states' in u.keys():\n",
    "            init_state = u['deductive_states'][0]\n",
    "            assert len(init_state) == 1\n",
    "            # init_state = from_dict(Goal, init_state[0])\n",
    "            for v in init_state[0]['variables']:\n",
    "                if '✝' in v['name']:\n",
    "                    anonymous_name_cnt[v['name']] += 1\n",
    "                    assert v['name'].replace('✝', '_') not in str(u['deductive_states'])\n",
    "            \n",
    "            submission = u['deductive_steps'][-1][-1][len('exact '):].strip()\n",
    "            if ' ' in submission or '.' in submission:\n",
    "                print(submission)\n",
    "                raise\n",
    "            else:\n",
    "                submission_cnt[submission] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83003c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = PersistentServer(\n",
    "    max_count=64,\n",
    "    is_state_based=True,\n",
    "    tag='',\n",
    "    _sync_init=False,\n",
    "    imports=[\"Mathlib\", \"Aesop\"],\n",
    "    project_path='/home/ma-user/workspace/formal_problem_generation/formal_problem_generation/data/MiniF2F',\n",
    "    core_options=CORE_OPTIONS,\n",
    "    timeout=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646ebbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "superscript_to_digit = {\n",
    "    '⁰': '0', '¹': '1', '²': '2', '³': '3', '⁴': '4',\n",
    "    '⁵': '5', '⁶': '6', '⁷': '7', '⁸': '8', '⁹': '9'\n",
    "}\n",
    "\n",
    "subscript_to_digit = {\n",
    "    '₀': '0', '₁': '1', '₂': '2', '₃': '3', '₄': '4',\n",
    "    '₅': '5', '₆': '6', '₇': '7', '₈': '8', '₉': '9'\n",
    "}\n",
    "\n",
    "digit_to_superscript = {v: k for k, v in superscript_to_digit.items()}\n",
    "digit_to_subscript = {v: k for k, v in subscript_to_digit.items()}\n",
    "\n",
    "allowed_prefices = ['h', 'h_']\n",
    "\n",
    "def generate_submission_name(name_list: List[str]) -> str:\n",
    "    # Parse names\n",
    "    numbers_existing = C.defaultdict(list)\n",
    "    for n in name_list:\n",
    "        for p in allowed_prefices:\n",
    "            if n.startswith(p):\n",
    "                num_str = n[len(p):]\n",
    "                if num_str == '':\n",
    "                    numbers_existing[-1].append((p, 'text'))\n",
    "                elif all(c in superscript_to_digit for c in num_str):\n",
    "                    num = int(''.join(superscript_to_digit[c] for c in num_str))\n",
    "                    numbers_existing[num].append((p, 'sup'))\n",
    "                elif all(c in subscript_to_digit for c in num_str):\n",
    "                    num = int(''.join(subscript_to_digit[c] for c in num_str))\n",
    "                    numbers_existing[num].append((p, 'sub'))\n",
    "                elif all(c.isascii() and c.isdigit() for c in num_str):\n",
    "                    num = int(num_str)\n",
    "                    numbers_existing[num].append((p, 'text'))\n",
    "                    \n",
    "    if not numbers_existing:\n",
    "        numbers_existing = C.defaultdict(list, {\n",
    "            -1: [('h', 'text')]\n",
    "        })\n",
    "    # Generate new name\n",
    "    max_number = sorted(numbers_existing.keys())[-1]\n",
    "    number_chosen = max_number + 1\n",
    "    prefix, format_type = random.choice(numbers_existing[max_number])\n",
    "    \n",
    "    if number_chosen == 0:\n",
    "        formatted_num = ''\n",
    "    else:\n",
    "        num_str = str(number_chosen)\n",
    "        if format_type == 'sup':\n",
    "            formatted_num = ''.join(digit_to_superscript[c] for c in num_str)\n",
    "        elif format_type == 'sub':\n",
    "            formatted_num = ''.join(digit_to_subscript[c] for c in num_str)\n",
    "        else:  # text\n",
    "            formatted_num = num_str\n",
    "    new_name = f\"{prefix}{formatted_num}\"\n",
    "    logger.debug(f'numbers_existing={numbers_existing}, max_number={number_chosen}, new_name={new_name}')\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c043a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = d\n",
    "base_cnt = 0\n",
    "idx = 0\n",
    "i_p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6569775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-20 22:17:52.983\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1masync_worker(0): 1/1 units to reasseblme\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import_list = datapoint['parse_result']['import_list']\n",
    "open_scoped_list = datapoint['parse_result']['open_scoped_list']\n",
    "open_list = datapoint['parse_result']['open_list']\n",
    "option_list = datapoint['parse_result']['option_list']\n",
    "units = datapoint['parse_result']['units']\n",
    "\n",
    "all_transformed_units = [i_u for i_u, u in enumerate(units) if 'deductive_steps' in units[i_u].keys()]\n",
    "remaining_units = [i_u for i_u in all_transformed_units if 'generation_process' not in units[i_u].keys()]\n",
    "logger.debug(f'async_worker({base_cnt+idx}): {len(remaining_units)}/{len(all_transformed_units)} units to reasseblme')\n",
    "if len(remaining_units) == 0:\n",
    "    raise\n",
    "\n",
    "tactic_header = ''\n",
    "load_header = ''\n",
    "if len(open_scoped_list):\n",
    "    tactic_header += 'open scoped ' + ' '.join(t for t in open_scoped_list) + ' in\\n'\n",
    "    load_header += 'open scoped ' + ' '.join(t for t in open_scoped_list) + '\\n'\n",
    "if len(open_list):\n",
    "    tactic_header += 'open ' + ' '.join(t for t in open_list) + ' in\\n'\n",
    "    load_header += 'open ' + ' '.join(t for t in open_list) + '\\n'\n",
    "if len(option_list):\n",
    "    tactic_header += '\\n'.join('set_option ' + t + ' in' for t in option_list) + '\\n'\n",
    "    load_header += '\\n'.join('set_option ' + t for t in option_list) + '\\n'\n",
    "\n",
    "# II. Reassemble trajectories\n",
    "agent = AutoregressiveProblemGenerationAgent(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21dde630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-20 22:17:53.042\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcommon.pantograph.server\u001b[0m:\u001b[36mcheck_restart_async\u001b[0m:\u001b[36m566\u001b[0m - \u001b[34m\u001b[1mPersistentServer(): Restarting...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "deductive_steps: List[Tuple[str, str]] = u['deductive_steps']\n",
    "deductive_states: List[List[Dict]] = u['deductive_states']\n",
    "if len(deductive_steps) == len(deductive_states):\n",
    "    deductive_states.append([])\n",
    "assert len(deductive_steps) + 1 == len(deductive_states)\n",
    "\n",
    "states: List[GoalState] = []\n",
    "steps: List[ProblemGenerationStep] = []\n",
    "cur_problem_state = await server.load_statement_async('False')\n",
    "states.append(cur_problem_state)\n",
    "\n",
    "# Execute introducing steps\n",
    "assert len(deductive_states[0]) == 1\n",
    "init_parsed_goal = dacite.from_dict(Goal, deductive_states[0][0])\n",
    "for v in init_parsed_goal.variables:\n",
    "    name = v.name\n",
    "    if '✝' in v.name:\n",
    "        assert v.name.replace('✝', '_') not in str(u['deductive_states'])\n",
    "        name = v.name.replace('✝', '_')\n",
    "    cur_step = ProblemGenerationStep(   # ProblemGenerationStepCategory.Introduce\n",
    "        step_draft=f'have {name} : {v.t} := sorry' if v.v is None else f'let {v.name} : {v.t} := {v.v}',\n",
    "        proof=None,\n",
    "        new_contexts=[]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    except (TacticFailure, ServerError):\n",
    "        cur_step.step_draft = tactic_header + cur_step.step_draft\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    assert len(new_problem_state.goals) == 1 and new_problem_state.goals[0].target == 'False', str(new_problem_state)\n",
    "    idents = set(cur_step.step.split())\n",
    "    for banned_token in BANNED_TOKENS[1:]:\n",
    "        if banned_token in idents:\n",
    "            logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Banned token \"{banned_token}\" in step \"{step_code}\"')\n",
    "    \n",
    "    cur_step.new_contexts = [\n",
    "        v for v in new_problem_state.goals[0].variables if\n",
    "            v.raw_name not in {vv.raw_name for vv in cur_problem_state.goals[0].variables}\n",
    "            # v not in forward_state.goals[0].variables\n",
    "    ]\n",
    "    if len(cur_step.new_contexts) != 1:\n",
    "        logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Strange introducing step: {str(cur_step)}')\n",
    "    \n",
    "    states.append(new_problem_state)\n",
    "    steps.append(cur_step)\n",
    "    cur_problem_state = new_problem_state\n",
    "\n",
    "if init_parsed_goal.variables != cur_problem_state.goals[0].variables:\n",
    "    logger.warning(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): init_parsed_goal.variables != cur_problem_state.goals[0].variables: {[str(init_parsed_goal), str(cur_problem_state.goals[0])]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790470f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x y : ℝ\n",
      "hx : x < 0\n",
      "hy : y < 0\n",
      "h1 : |y| = 6\n",
      "h2 : √((x - 8) ^ 2 + (y - 3) ^ 2) = 15\n",
      "n : ℕ\n",
      "hn : n > 0\n",
      "h3 : √(x ^ 2 + y ^ 2) = √↑n\n",
      "⊢ False\n",
      "9 10\n"
     ]
    }
   ],
   "source": [
    "print(cur_problem_state)\n",
    "print(len(steps), len(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c143819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute deriving steps\n",
    "for ((step_header, step_code), next_parsed_state) in zip(deductive_steps[:-1], deductive_states[1:-1]):\n",
    "    assert len(next_parsed_state) == 1\n",
    "    next_parsed_goal = dacite.from_dict(Goal, next_parsed_state[0])\n",
    "    cur_step = ProblemGenerationStep(   # ProblemGenerationStepCategory.Derive\n",
    "        step_draft=step_header + step_code,\n",
    "        proof=[],\n",
    "        new_contexts=[]\n",
    "    )\n",
    "    \n",
    "    new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    assert len(new_problem_state.goals) == 1 and new_problem_state.goals[0].target == 'False', str(new_problem_state)\n",
    "    idents = set(cur_step.step.split())\n",
    "    for banned_token in BANNED_TOKENS:\n",
    "        if banned_token in idents:\n",
    "            logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Banned token \"{banned_token}\" in step \"{step_code}\"')\n",
    "            \n",
    "    cur_step.new_contexts = [\n",
    "        v for v in new_problem_state.goals[0].variables if\n",
    "            v.raw_name not in {vv.raw_name for vv in cur_problem_state.goals[0].variables}\n",
    "            # v not in forward_state.goals[0].variables\n",
    "    ]\n",
    "    if len(cur_step.new_contexts) == 0:\n",
    "        logger.warning(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Unused step: {str(cur_step)}')\n",
    "    \n",
    "    states.append(new_problem_state)\n",
    "    steps.append(cur_step)\n",
    "    cur_problem_state = new_problem_state\n",
    "\n",
    "    if next_parsed_goal.variables != cur_problem_state.goals[0].variables:\n",
    "        logger.warning(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): next_parsed_goal.variables != cur_problem_state.goals[0].variables: {[str(next_parsed_goal), str(cur_problem_state.goals[0])]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a646b288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x y : ℝ\n",
      "hx : x < 0\n",
      "hy✝ : y < 0\n",
      "h1 : |y| = 6\n",
      "h2 : √((x - 8) ^ 2 + (y - 3) ^ 2) = 15\n",
      "n : ℕ\n",
      "hn : n > 0\n",
      "h3 : √(x ^ 2 + y ^ 2) = √↑n\n",
      "this✝ : (x - 8) ^ 2 + (y - 3) ^ 2 = ↑(15 ^ 2)\n",
      "hy : y = -6\n",
      "this : x ^ 2 + y ^ 2 = 52\n",
      "eq : 52 = n\n",
      "⊢ False\n"
     ]
    }
   ],
   "source": [
    "print(cur_problem_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2869cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-20 22:18:02.724\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_submission_name\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mnumbers_existing=defaultdict(<class 'list'>, {1: [('h', 'text')], 2: [('h', 'text')], 3: [('h', 'text')]}), max_number=4, new_name=h4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Execute submitting step\n",
    "assert len(deductive_states[-1]) == 0\n",
    "step_code = remove_comments(deductive_steps[-1][-1]).strip()\n",
    "assert step_code.startswith('exact '), step_code\n",
    "submission_name = step_code[len('exact '):]\n",
    "\n",
    "if ' ' in submission_name or '.' in submission_name:\n",
    "    new_name = generate_submission_name([v.name for v in cur_problem_state.goals[0].variables if v.name is not None])\n",
    "    cur_step = ProblemGenerationStep(   # ProblemGenerationStepCategory.Derive\n",
    "        step_draft=f'have {new_name} : {init_parsed_goal.target} := {submission_name}',\n",
    "        proof=[],\n",
    "        new_contexts=[]\n",
    "    )\n",
    "    submission_name = new_name\n",
    "    \n",
    "    try:\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    except (TacticFailure, ServerError):\n",
    "        cur_step.step_draft = tactic_header + cur_step.step_draft\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    assert len(new_problem_state.goals) == 1 and new_problem_state.goals[0].target == 'False', str(new_problem_state)\n",
    "    idents = set(cur_step.step.split())\n",
    "    for banned_token in BANNED_TOKENS:\n",
    "        if banned_token in idents:\n",
    "            logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Banned token \"{banned_token}\" in step \"{step_code}\"')\n",
    "    \n",
    "    cur_step.new_contexts = [\n",
    "        v for v in new_problem_state.goals[0].variables if\n",
    "            v.raw_name not in {vv.raw_name for vv in cur_problem_state.goals[0].variables}\n",
    "            # v not in forward_state.goals[0].variables\n",
    "    ]\n",
    "    if len(cur_step.new_contexts) == 0:\n",
    "        logger.warning(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Unused step: {str(cur_step)}')\n",
    "    \n",
    "    states.append(new_problem_state)\n",
    "    steps.append(cur_step)\n",
    "    cur_problem_state = new_problem_state\n",
    "\n",
    "assert submission_name in [v.name for v in cur_problem_state.goals[0].variables], f'submission_name={submission_name}, cur_problem_state={cur_problem_state}'\n",
    "steps.append(\n",
    "    ProblemGenerationStep(   # ProblemGenerationStepCategory.Submit\n",
    "        step_draft=f'submit_answer {submission_name}',\n",
    "        proof=None,\n",
    "        new_contexts=None\n",
    "    )\n",
    ")\n",
    "\n",
    "# Parsed trajectory\n",
    "result = ProblemGenerationProcess(\n",
    "    informal_problem='',\n",
    "    informal_answer='',\n",
    "    informal_solution='',\n",
    "    header=None,\n",
    "    formal_statement='',\n",
    "    formal_solution_draft='',\n",
    "    formal_proofs='',\n",
    "    steps=steps,\n",
    "    dependencies=[],\n",
    "    trajectory=[(S.goals[0].variables, i) for i, S in enumerate(states)],\n",
    "    metainfo=dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "933d33ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x y : ℝ\n",
      "hx : x < 0\n",
      "hy✝ : y < 0\n",
      "h1 : |y| = 6\n",
      "h2 : √((x - 8) ^ 2 + (y - 3) ^ 2) = 15\n",
      "n : ℕ\n",
      "hn : n > 0\n",
      "h3 : √(x ^ 2 + y ^ 2) = √↑n\n",
      "this✝ : (x - 8) ^ 2 + (y - 3) ^ 2 = ↑(15 ^ 2)\n",
      "hy : y = -6\n",
      "this : x ^ 2 + y ^ 2 = 52\n",
      "eq : 52 = n\n",
      "h4 : n = 52\n",
      "⊢ False\n"
     ]
    }
   ],
   "source": [
    "print(cur_problem_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ca3632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProblemGenerationStep(step_draft='have h4 : n = 52 := eq.symm', proof=[], new_contexts=[Variable(t='n = 52', v=None, name='h4')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2920f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProblemGenerationStep(step_draft='submit_answer h4', proof=None, new_contexts=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5120a82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(states), len(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22da35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassemble trajectory\n",
    "is_analyzed = await agent.analyze_async(\n",
    "    result=result,\n",
    "    states=states,\n",
    "    server=server,\n",
    "    tag=str(base_cnt+idx),\n",
    "    reassemble_trajectory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e05c3d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da35dab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result.metainfo = json.dumps(result.metainfo | {\u001b[33m'\u001b[39m\u001b[33mtime_consumption\u001b[39m\u001b[33m'\u001b[39m: time.time() - \u001b[43mtime_start\u001b[49m})\n\u001b[32m      3\u001b[39m u[\u001b[33m'\u001b[39m\u001b[33mgeneration_process\u001b[39m\u001b[33m'\u001b[39m] = result\n\u001b[32m      4\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33masync_worker(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_cnt+idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_p\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(remaining_units)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): succeeded.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'time_start' is not defined"
     ]
    }
   ],
   "source": [
    "result.metainfo = json.dumps(result.metainfo | {'time_consumption': time.time() - time_start})\n",
    "\n",
    "u['generation_process'] = result\n",
    "logger.debug(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): succeeded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bdf89",
   "metadata": {},
   "source": [
    "### Data Composition - Deductive Proof Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_lengths = []\n",
    "for d in data_parsed:\n",
    "    for u in d['parse_result']['units']:\n",
    "        if 'deductive_steps' in u.keys():\n",
    "            assert len(u['invocations'] or []) > 0\n",
    "            proof_lengths.append(len(u['deductive_steps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.Counter(proof_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# bins: Number of intervals to group integers (adjust based on your data range)\n",
    "plt.hist(proof_lengths, bins=40, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Proof Length', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_deductive_proof_generation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73df803",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = (\"\"\"\n",
    "import Mathlib\n",
    "import Aesop\n",
    "\n",
    "\"\"\" + '\\n'.join('set_option ' + t.replace('=', ' ') for t in CORE_OPTIONS)).strip()\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097dc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_parsed:\n",
    "    for u in d['parse_result']['units']:\n",
    "        if 'deductive_steps' in u.keys():\n",
    "            assert len(u['invocations'] or []) > 0\n",
    "            \n",
    "            init_state = u['deductive_states'][0]\n",
    "            assert len(init_state) == 1\n",
    "            init_state = from_dict(Goal, init_state[0])\n",
    "            \n",
    "            whole_proof = u['whole_proof']\n",
    "            if whole_proof is None:\n",
    "                # There is only one `whole_proof is None`, and is manually validated by Qi\n",
    "                whole_proof = ''\n",
    "                for t, s in u['deductive_steps']:\n",
    "                    if len(t) > 0:\n",
    "                        whole_proof += t\n",
    "                    whole_proof += s + '\\n\\n'\n",
    "                whole_proof = whole_proof.strip()\n",
    "            \n",
    "            data_deductive_proof_generation.append({\n",
    "                \"conversation\":[\n",
    "                    {\n",
    "                        \"input\": f\"\"\"\n",
    "Assume the following header is executed:\n",
    "```lean4\n",
    "{header}\n",
    "```\n",
    "\n",
    "Generate a deductive proof for the following Lean 4 proof state:\n",
    "```lean4\n",
    "{str(init_state)}\n",
    "```\n",
    "\"\"\".strip(),\n",
    "                        \"output\": whole_proof\n",
    "                    }\n",
    "                ]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_xtuner_sample(random.choice(data_deductive_proof_generation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/deductive_proof_generation.40069.jsonl', 'w') as f:\n",
    "    for d in data_deductive_proof_generation:\n",
    "        f.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3cd93",
   "metadata": {},
   "source": [
    "### Data Composition - Autoregressive Problem Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6f27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SYSTEM_PROMPT_FPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b16567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_step(self):\n",
    "    if self.proof is None:\n",
    "        return self.step_draft\n",
    "    else:\n",
    "        normalized_step_draft = normalize_draft(self.step_draft)\n",
    "        matches = list(re.finditer(':= sorry', normalized_step_draft))\n",
    "        assert len(matches) == len(self.proof)\n",
    "        for (m, p) in reversed(list(zip(matches, self.proof))):\n",
    "            normalized_step_draft = replace_span(m.span(), ':= by {\\n' + '\\n'.join('  ' + l for l in p.splitlines()) + '\\n}', normalized_step_draft)\n",
    "        return normalized_step_draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_forward_solution_step_prompt(d: ProblemGenerationProcess, state: List[Variable]) -> str:\n",
    "    context = ''\n",
    "    vars_to_format = [v for v in state]\n",
    "    while len(vars_to_format) > 0:\n",
    "        for i in range(len(vars_to_format)):\n",
    "            if i + 1 == len(vars_to_format) or not (vars_to_format[i].t == vars_to_format[i+1].t and vars_to_format[i].v is None and vars_to_format[i+1].v is None):\n",
    "                break\n",
    "        if i == 0:\n",
    "            context += str(vars_to_format[0]) + '\\n'\n",
    "            vars_to_format.pop(0)\n",
    "        else:\n",
    "            context += ' '.join([v.name if v.name is not None else \"_\" for v in vars_to_format[:i+1]]) + f' : {vars_to_format[0].t}\\n'\n",
    "            vars_to_format = vars_to_format[i+1:]\n",
    "    \n",
    "    prompt = f'''Given a Lean 4 context, propose the single most natural next step to explore toward a beautiful conclusion — either\n",
    "- derive a new intermediate fact,\n",
    "- introduce a fresh variable or hypothesis, or\n",
    "- submit one of the local facts as the final answer.\n",
    "\n",
    "Requirements\n",
    "1. Flavoured {d.metainfo['problem_type']} and suitable for posting on forums about {d.metainfo['source']}.\n",
    "2. Fully formal Lean 4 code (inline comments in natural language are fine for planning and reasoning). Assume `import Mathlib`.\n",
    "\n",
    "\n",
    "# Lean 4 Context\n",
    "```lean4\n",
    "{context.rstrip()}\n",
    "```\n",
    "'''\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def format_forward_solution_step_response(d: ProblemGenerationProcess, step: ProblemGenerationStep):\n",
    "    step_type = 'Derive' if step.is_deducing else 'Introduce' if step.is_introducing else 'Submit'\n",
    "    response = f'''# Step {step_type}\n",
    "```lean4\n",
    "{format_step(step).rstrip()}\n",
    "```\n",
    "'''\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_problem_generation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b412443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(data_nonsynthetic_n15):\n",
    "    for p in d.trajectory:\n",
    "        data_problem_generation.append({\n",
    "            \"conversation\":[\n",
    "                {\n",
    "                    \"system\": SYSTEM_PROMPT_FPG,\n",
    "                    \"input\": format_forward_solution_step_prompt(d, p[0]),\n",
    "                    \"output\": format_forward_solution_step_response(d, d.steps[p[1]])\n",
    "                }\n",
    "            ]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a483b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_problem_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/sfs/liuqi/data/AI-MO/NuminaMath-1.5/cycle123_problem_generation_steps.jsonl', 'w') as f:\n",
    "    for s in data_problem_generation:\n",
    "        f.write(json.dumps(s) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_forward_solution_step_prompt(d, p[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b30e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_forward_solution_step_response(d, d.steps[p[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf08d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a241b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
