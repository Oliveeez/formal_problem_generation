{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fb9cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/nnae/latest owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/nnae/8.2.RC1/ascend_nnae_install.info owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/__init__.py:289: UserWarning: On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default.                      Do not set it to 1 to prevent some unknown errors\n",
      "  warnings.warn(\"On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default. \\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import pickle\n",
    "import collections as C\n",
    "import itertools as I\n",
    "import random\n",
    "import regex as re\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "import time\n",
    "\n",
    "import msgspec\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from dacite import from_dict\n",
    "import dacite\n",
    "\n",
    "from common.constants import SYSTEM_PROMPT_FPG, CORE_OPTIONS, BANNED_TOKENS\n",
    "from common.utils import remove_comments, replace_sorry, replace_calc, remove_multiline_comments, remove_singleline_comments, parse_idents, normalize_spaces\n",
    "from common.pantograph.dataclasses import ProblemGenerationProcess, ProblemGenerationStep, Variable, normalize_draft, replace_span, Goal, GoalState, ProblemGenerationStep, ProblemGenerationProcess, TacticDraft\n",
    "from common.pantograph.server import PersistentServer, TacticFailure, ServerError\n",
    "from agent.problem_generation import AutoregressiveProblemGenerationAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0685e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bracket_pairings = {\n",
    "    '(' : ')',\n",
    "    '[' : ']',\n",
    "    '{' : '}',\n",
    "    '⦃' : '⦄'\n",
    "}\n",
    "\n",
    "def parse_variables(s : str) -> Tuple[str, str]:\n",
    "    base = 0\n",
    "    variables = []\n",
    "    target = None\n",
    "    while base < len(s):\n",
    "        if s[base] in ['(', '[', '{', '⦃']:\n",
    "            bracket_type = s[base]\n",
    "            bracket_pairing = bracket_pairings[bracket_type]\n",
    "        \n",
    "            stack_cnt = 0\n",
    "            start_end_positions = []\n",
    "\n",
    "            for i, char in enumerate(s[base:]):\n",
    "                if char == bracket_type:\n",
    "                    if stack_cnt == 0:\n",
    "                        start_position = i\n",
    "                    stack_cnt += 1\n",
    "                elif char == bracket_pairing:\n",
    "                    if stack_cnt > 0:\n",
    "                        stack_cnt -= 1\n",
    "                        if stack_cnt == 0:\n",
    "                            end_position = i\n",
    "                            start_end_positions.append((start_position, end_position))\n",
    "                            break\n",
    "            \n",
    "            start, end = start_end_positions[0]\n",
    "            variables.append(s[base+start:base+end+1])\n",
    "            base += i\n",
    "        else:\n",
    "            if s[base] == ',':\n",
    "                target = s[base+1:].strip()\n",
    "                break\n",
    "            base += 1\n",
    "    \n",
    "    return variables, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e219d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_xtuner_sample(data: list):\n",
    "    if 'system' in data['conversation'][0].keys():\n",
    "        print('<SYSTEM>')\n",
    "        print(data['conversation'][0]['system'])\n",
    "        print('</SYSTEM>')\n",
    "    print('<INPUT>')\n",
    "    print(data['conversation'][0]['input'])\n",
    "    print('</INPUT>\\n<OUTPUT>')\n",
    "    print(data['conversation'][0]['output'])\n",
    "    print('</OUTPUT>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a5c7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:54<00:00,  2.80s/it]\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/deductive_transformation'\n",
    "data = []\n",
    "\n",
    "for i in tqdm(list(range(41))):\n",
    "    with open(osp.join(base_dir, f'reassembled_fixed_chunk_{1024*i}.pkl'), 'rb') as f:\n",
    "        data.extend(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0959d9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41109 39840 1269\n"
     ]
    }
   ],
   "source": [
    "data_parsed = [d for d in data if d is not None]\n",
    "assert all('parse_result' in d.keys() for d in data_parsed)\n",
    "print(len(data), len(data_parsed), len(data)-len(data_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c4c3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uuid', 'problem', 'question_type', 'answer', 'author', 'formal_statement', 'ground_truth_type', 'rl_data', 'source', 'problem_type', 'exam', 'formal_code', 'parse_result'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parsed[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb913e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('Algebra', 'olympiads'): 9998,\n",
       "         ('unknown', 'unknown'): 5577,\n",
       "         ('Number Theory', 'olympiads'): 4703,\n",
       "         ('Inequalities', 'olympiads'): 2391,\n",
       "         ('Algebra', 'secondary_math'): 2278,\n",
       "         ('Algebra', 'math_train'): 1523,\n",
       "         ('Algebra', 'math_test'): 1205,\n",
       "         ('Algebra', 'amc_aime'): 1116,\n",
       "         ('Number Theory', 'aops_forum'): 976,\n",
       "         ('Algebra', 'olympiads_ref'): 931,\n",
       "         ('Inequalities', 'inequalities'): 855,\n",
       "         ('Inequalities', 'aops_forum'): 825,\n",
       "         ('Number Theory', 'olympiads_ref'): 760,\n",
       "         ('Algebra', 'cn_k12'): 641,\n",
       "         ('Number Theory', 'number_theory'): 565,\n",
       "         ('Number Theory', 'synthetic'): 542,\n",
       "         ('Algebra', 'aops_forum'): 518,\n",
       "         ('Inequalities', 'secondary_math'): 465,\n",
       "         ('Number Theory', 'math_train'): 434,\n",
       "         ('Number Theory', 'secondary_math'): 432,\n",
       "         ('Calculus', 'olympiads'): 423,\n",
       "         ('Number Theory', 'amc_aime'): 393,\n",
       "         ('Inequalities', 'olympiads_ref'): 307,\n",
       "         ('Number Theory', 'math_test'): 258,\n",
       "         ('Algebra', 'cn_contest'): 240,\n",
       "         ('Algebra', 'inequalities'): 176,\n",
       "         ('NaN', 'olympiads'): 165,\n",
       "         ('Number Theory', 'cn_contest'): 149,\n",
       "         ('Other', 'olympiads_ref'): 115,\n",
       "         ('Combinatorics', 'olympiads_ref'): 113,\n",
       "         ('Calculus', 'aops_forum'): 92,\n",
       "         ('Calculus', 'math_test'): 91,\n",
       "         ('Other', 'olympiads'): 86,\n",
       "         ('Calculus', 'math_train'): 81,\n",
       "         ('Inequalities', 'cn_contest'): 51,\n",
       "         ('Other', 'aops_forum'): 47,\n",
       "         ('Geometry', 'olympiads_ref'): 38,\n",
       "         ('Algebra', 'unknown'): 30,\n",
       "         ('Calculus', 'olympiads_ref'): 26,\n",
       "         ('Inequalities', 'amc_aime'): 24,\n",
       "         ('Number Theory', 'inequalities'): 23,\n",
       "         ('NaN', 'aops_forum'): 22,\n",
       "         ('Algebra', 'number_theory'): 19,\n",
       "         ('Geometry', 'amc_aime'): 18,\n",
       "         ('Calculus', 'secondary_math'): 17,\n",
       "         ('NaN', 'amc_aime'): 12,\n",
       "         ('Number Theory', 'unknown'): 8,\n",
       "         ('Logic and Puzzles', 'olympiads_ref'): 8,\n",
       "         ('Intermediate Algebra', 'unknown'): 8,\n",
       "         ('Calculus', 'cn_contest'): 6,\n",
       "         ('Combinatorics', 'amc_aime'): 5,\n",
       "         ('Linear Algebra', 'unknown'): 4,\n",
       "         ('Logic and Puzzles', 'amc_aime'): 4,\n",
       "         ('Calculus', 'inequalities'): 4,\n",
       "         ('Geometry', 'olympiads'): 4,\n",
       "         ('Other', 'secondary_math'): 4,\n",
       "         ('Precalculus', 'unknown'): 3,\n",
       "         ('Trigonometry', 'unknown'): 3,\n",
       "         ('Arithmetic', 'unknown'): 3,\n",
       "         ('Functional Equations', 'unknown'): 3,\n",
       "         ('Calculus', 'unknown'): 3,\n",
       "         ('Recursion Other', 'unknown'): 2,\n",
       "         ('Logic and Puzzles', 'unknown'): 2,\n",
       "         ('Other', 'amc_aime'): 2,\n",
       "         ('Inequalities', 'cn_k12'): 2,\n",
       "         ('Inequalities', 'number_theory'): 2,\n",
       "         ('Number Theory', 'cn_k12'): 2,\n",
       "         ('Logic and Puzzles', 'olympiads'): 2,\n",
       "         ('Other', 'number_theory'): 2,\n",
       "         ('Inequalities', 'unknown'): 1,\n",
       "         ('Calculus', 'amc_aime'): 1,\n",
       "         ('Algebra', 'synthetic'): 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.Counter(\n",
    "    (d['problem_type'], d['source']) for d in data_parsed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb835742",
   "metadata": {},
   "source": [
    "### Informalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9626a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "informalization = []\n",
    "\n",
    "for d in data_parsed:\n",
    "    u = d['parse_result']['units'][-1]\n",
    "    if len(u['invocations'] or []) == 0 or 'deductive_steps' not in u.keys():\n",
    "        continue\n",
    "    formal_statement = u['formal_statement']\n",
    "    load_header = u['load_header']\n",
    "    variables = []\n",
    "    if formal_statement.startswith('∀ '):\n",
    "        context, target = parse_variables(formal_statement[len('∀ '):])\n",
    "    else:\n",
    "        target = formal_statement.strip()\n",
    "\n",
    "    new_formal_statement = 'example\\n' + (('\\n'.join(context) + '\\n') if len(context) > 0 else '') + ': ' + target + '\\n:= sorry'\n",
    "\n",
    "    informalization.append({k : v for (k, v) in d.items() if k != 'parse_result'} | {\n",
    "        'formal_statement': new_formal_statement,\n",
    "        'deductive_steps': '\\n\\n'.join(s[0] + s[1] for s in u['deductive_steps'])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join('/cache/workspace/formal_problem_generation/data/Numina-Lean', 'data_parsed_stmt_w_dstesp.0825.jsonl'), 'w') as f:\n",
    "    for d in informalization:\n",
    "        f.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f507ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(informalization))\n",
    "informalization[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b750c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(informalization[0]['formal_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025267d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(informalization[0]['deductive_steps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f60b4",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_units = 0\n",
    "n_transformed_units = 0\n",
    "n_deductive_units = 0\n",
    "n_reassembled_units = 0\n",
    "\n",
    "transformed_units = []\n",
    "\n",
    "for d in data_parsed:\n",
    "    units = d['parse_result']['units']\n",
    "    all_parsed_units = [i_u for i_u, u in enumerate(units) if len(u['invocations'] or []) > 0]\n",
    "    transformed_units.extend([units[i_u] for i_u in all_parsed_units if 'deductive_steps' in units[i_u].keys()])\n",
    "\n",
    "    n_total_units += len(all_parsed_units)\n",
    "\n",
    "deductive_units = [u for u in transformed_units if 'generation_process' in u.keys()] # Successfully execited w/ `False` target\n",
    "reassembled_units = [u for u in deductive_units if 'original_trajectory' in u['generation_process'].metainfo] # Successfully execited w/ `False` target\n",
    "    \n",
    "\n",
    "print(n_total_units, len(transformed_units), len(deductive_units), len(reassembled_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b062f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonymous_name_cnt = C.Counter()\n",
    "# submission_cnt = C.Counter()\n",
    "\n",
    "# for d in data_parsed:\n",
    "#     for u in d['parse_result']['units']:\n",
    "#         if 'deductive_states' in u.keys():\n",
    "#             init_state = u['deductive_states'][0]\n",
    "#             assert len(init_state) == 1\n",
    "#             # init_state = from_dict(Goal, init_state[0])\n",
    "#             for v in init_state[0]['variables']:\n",
    "#                 if '✝' in v['name']:\n",
    "#                     anonymous_name_cnt[v['name']] += 1\n",
    "#                     assert v['name'].replace('✝', '_') not in str(u['deductive_states'])\n",
    "            \n",
    "#             submission = u['deductive_steps'][-1][-1][len('exact '):].strip()\n",
    "#             if ' ' in submission or '.' in submission:\n",
    "#                 print(submission)\n",
    "#                 raise\n",
    "#             else:\n",
    "#                 submission_cnt[submission] += 1\n",
    "\n",
    "# for (i, d) in enumerate(data_parsed):\n",
    "#     if r'''theorem number_theory_4780 {a b p x : ℕ} ''' in d['formal_statement']:\n",
    "#         break\n",
    "# print(i)\n",
    "# print(d['formal_statement'])\n",
    "\n",
    "for i, d in enumerate(data_parsed):\n",
    "    units = d['parse_result']['units']\n",
    "    for i_u, u in enumerate(units):\n",
    "        if len(u['invocations'] or []) > 0:\n",
    "            if 'deductive_steps' in u.keys() and 'generation_process' not in u.keys():\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83003c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = PersistentServer(\n",
    "    max_count=64,\n",
    "    is_state_based=True,\n",
    "    tag='',\n",
    "    _sync_init=False,\n",
    "    imports=[\"Mathlib\", \"Aesop\"],\n",
    "    project_path='/home/ma-user/workspace/formal_problem_generation/formal_problem_generation/data/MiniF2F',\n",
    "    core_options=CORE_OPTIONS,\n",
    "    timeout=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ebbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "superscript_to_digit = {\n",
    "    '⁰': '0', '¹': '1', '²': '2', '³': '3', '⁴': '4',\n",
    "    '⁵': '5', '⁶': '6', '⁷': '7', '⁸': '8', '⁹': '9'\n",
    "}\n",
    "\n",
    "subscript_to_digit = {\n",
    "    '₀': '0', '₁': '1', '₂': '2', '₃': '3', '₄': '4',\n",
    "    '₅': '5', '₆': '6', '₇': '7', '₈': '8', '₉': '9'\n",
    "}\n",
    "\n",
    "digit_to_superscript = {v: k for k, v in superscript_to_digit.items()}\n",
    "digit_to_subscript = {v: k for k, v in subscript_to_digit.items()}\n",
    "\n",
    "allowed_prefices = ['h', 'h_']\n",
    "\n",
    "def generate_submission_name(name_list: List[str]) -> str:\n",
    "    # Parse names\n",
    "    numbers_existing = C.defaultdict(list)\n",
    "    for n in name_list:\n",
    "        for p in allowed_prefices:\n",
    "            if n.startswith(p):\n",
    "                num_str = n[len(p):]\n",
    "                if num_str == '':\n",
    "                    numbers_existing[-1].append((p, 'text'))\n",
    "                elif all(c in superscript_to_digit for c in num_str):\n",
    "                    num = int(''.join(superscript_to_digit[c] for c in num_str))\n",
    "                    numbers_existing[num].append((p, 'sup'))\n",
    "                elif all(c in subscript_to_digit for c in num_str):\n",
    "                    num = int(''.join(subscript_to_digit[c] for c in num_str))\n",
    "                    numbers_existing[num].append((p, 'sub'))\n",
    "                elif all(c.isascii() and c.isdigit() for c in num_str):\n",
    "                    num = int(num_str)\n",
    "                    numbers_existing[num].append((p, 'text'))\n",
    "                    \n",
    "    if not numbers_existing:\n",
    "        numbers_existing = C.defaultdict(list, {\n",
    "            -1: [('h', 'text')]\n",
    "        })\n",
    "    # Generate new name\n",
    "    max_number = sorted(numbers_existing.keys())[-1]\n",
    "    number_chosen = max_number + 1\n",
    "    prefix, format_type = random.choice(numbers_existing[max_number])\n",
    "    \n",
    "    if number_chosen == 0:\n",
    "        formatted_num = ''\n",
    "    else:\n",
    "        num_str = str(number_chosen)\n",
    "        if format_type == 'sup':\n",
    "            formatted_num = ''.join(digit_to_superscript[c] for c in num_str)\n",
    "        elif format_type == 'sub':\n",
    "            formatted_num = ''.join(digit_to_subscript[c] for c in num_str)\n",
    "        else:  # text\n",
    "            formatted_num = num_str\n",
    "    new_name = f\"{prefix}{formatted_num}\"\n",
    "    logger.debug(f'numbers_existing={numbers_existing}, max_number={number_chosen}, new_name={new_name}')\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = d\n",
    "base_cnt = 0\n",
    "idx = 0\n",
    "i_p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_list = datapoint['parse_result']['import_list']\n",
    "open_scoped_list = datapoint['parse_result']['open_scoped_list']\n",
    "open_list = datapoint['parse_result']['open_list']\n",
    "option_list = datapoint['parse_result']['option_list']\n",
    "units = datapoint['parse_result']['units']\n",
    "\n",
    "all_transformed_units = [i_u for i_u, u in enumerate(units) if 'deductive_steps' in units[i_u].keys()]\n",
    "remaining_units = [i_u for i_u in all_transformed_units if 'generation_process' not in units[i_u].keys()]\n",
    "logger.debug(f'async_worker({base_cnt+idx}): {len(remaining_units)}/{len(all_transformed_units)} units to reasseblme')\n",
    "if len(remaining_units) == 0:\n",
    "    raise\n",
    "\n",
    "tactic_header = ''\n",
    "load_header = ''\n",
    "if len(open_scoped_list):\n",
    "    tactic_header += 'open scoped ' + ' '.join(t for t in open_scoped_list) + ' in\\n'\n",
    "    load_header += 'open scoped ' + ' '.join(t for t in open_scoped_list) + '\\n'\n",
    "if len(open_list):\n",
    "    tactic_header += 'open ' + ' '.join(t for t in open_list) + ' in\\n'\n",
    "    load_header += 'open ' + ' '.join(t for t in open_list) + '\\n'\n",
    "if len(option_list):\n",
    "    tactic_header += '\\n'.join('set_option ' + t + ' in' for t in option_list) + '\\n'\n",
    "    load_header += '\\n'.join('set_option ' + t for t in option_list) + '\\n'\n",
    "\n",
    "# II. Reassemble trajectories\n",
    "agent = AutoregressiveProblemGenerationAgent(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d300d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = units[remaining_units[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dde630",
   "metadata": {},
   "outputs": [],
   "source": [
    "deductive_steps: List[Tuple[str, str]] = u['deductive_steps']\n",
    "deductive_states: List[List[Dict]] = u['deductive_states']\n",
    "if len(deductive_states[-1]) != 0:  #* Caused by a bug in `numina-lean.deductive_transform-decompose.py` (fixed in `e657161`)\n",
    "    for i in reversed(list(range(1, len(deductive_states)))):\n",
    "        if deductive_states[i] == deductive_states[i-1]:\n",
    "            break\n",
    "    if deductive_states[i] == deductive_states[i-1]:\n",
    "        logger.debug(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Removing {i}-th state (duplicated)')\n",
    "        deductive_states.pop(i)\n",
    "    deductive_states.append([])\n",
    "if len(deductive_steps) + 1 != len(deductive_states):\n",
    "    logger.warning(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): len(deductive_steps) + 1 != len(deductive_states): {len(deductive_steps)}, {len(deductive_states)}')\n",
    "\n",
    "states: List[GoalState] = []\n",
    "steps: List[ProblemGenerationStep] = []\n",
    "cur_problem_state = await server.load_statement_async('False')\n",
    "states.append(cur_problem_state)\n",
    "\n",
    "# Execute introducing steps\n",
    "assert len(deductive_states[0]) == 1\n",
    "\n",
    "init_parsed_goal = dacite.from_dict(Goal, deductive_states[0][0])\n",
    "var_type_dict = {\n",
    "    v.name : v.t for v in init_parsed_goal.variables\n",
    "}\n",
    "var_value_dict = {\n",
    "    v.name : v.v for v in init_parsed_goal.variables\n",
    "}\n",
    "\n",
    "# Break from formal statement\n",
    "formal_statement = u['formal_statement']\n",
    "variables = []\n",
    "if formal_statement.startswith('∀ '):\n",
    "    context, target = parse_variables(formal_statement[len('∀ '):])\n",
    "    for declaration in context:\n",
    "        if declaration[0] == '[':\n",
    "            try:\n",
    "                var_names, var_type = declaration[1:-1].split(':', 1)\n",
    "            except ValueError:\n",
    "                var_names = '_'\n",
    "                var_type = declaration[1:-1]\n",
    "            for name in var_names.strip().split():\n",
    "                print(name, var_type)\n",
    "                variables.append((name.strip(), var_type))\n",
    "        else:\n",
    "            assert '✝' not in declaration, f'declaration: {declaration}'\n",
    "            try:\n",
    "                var_names, var_type = declaration[1:-1].split(':', 1)\n",
    "            except ValueError:\n",
    "                var_names = declaration[1:-1]\n",
    "                var_type = None\n",
    "            for name in var_names.strip().split():\n",
    "                if '✝' in name:\n",
    "                    logger.critical(f\"async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): '✝' in name: {[formal_statement]}\")\n",
    "                    name = '_'\n",
    "                variables.append((name.strip(), var_type or var_type_dict[name.strip()]))\n",
    "else:\n",
    "    target = formal_statement.strip()\n",
    "\n",
    "for (name, var_type) in variables:\n",
    "    # name = v.name\n",
    "    # decl = v.t\n",
    "    # if '✝' in v.name:\n",
    "    #     assert v.name.replace('✝', '_') not in str(u['deductive_states'])\n",
    "    #     name = v.name.replace('✝', '_')\n",
    "    # if decl.startswith('Type u_'):\n",
    "    #     decl = 'Type*'\n",
    "    # elif decl.startswith('Sort u*'):\n",
    "    #     decl = 'Sort*'\n",
    "    cur_step = ProblemGenerationStep(   # ProblemGenerationStepCategory.Introduce\n",
    "        step_draft=f'have {name} : {var_type} := sorry', # if var_value_dict[name] is None else f'let {name} : {var_type} := {var_value_dict[name]}'\n",
    "        proof=None,\n",
    "        new_contexts=[]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    except (TacticFailure, ServerError):\n",
    "        cur_step.step_draft = tactic_header + cur_step.step_draft\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    assert len(new_problem_state.goals) == 1 and new_problem_state.goals[0].target == 'False', str(new_problem_state)\n",
    "    idents = set(cur_step.step.split())\n",
    "    for banned_token in BANNED_TOKENS[1:]:\n",
    "        if banned_token in idents:\n",
    "            logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Banned token \"{banned_token}\" in step \"{step_code}\"')\n",
    "    \n",
    "    cur_step.new_contexts = [\n",
    "        v for v in new_problem_state.goals[0].variables if\n",
    "            v.raw_name not in {vv.raw_name for vv in cur_problem_state.goals[0].variables}\n",
    "            # v not in forward_state.goals[0].variables\n",
    "    ]\n",
    "    if len(cur_step.new_contexts) != 1:\n",
    "        logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Strange introducing step: {str(cur_step)}')\n",
    "    \n",
    "    states.append(new_problem_state)\n",
    "    steps.append(cur_step)\n",
    "    cur_problem_state = new_problem_state\n",
    "\n",
    "if init_parsed_goal.variables != cur_problem_state.goals[0].variables:\n",
    "    logger.debug(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): init_parsed_goal.variables != cur_problem_state.goals[0].variables: {[str(init_parsed_goal), str(cur_problem_state.goals[0])]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in deductive_states:\n",
    "#     assert len(s) <= 1\n",
    "#     print('---\\n' + '\\n'.join(str(dacite.from_dict(Goal, g)) for g in s) + '\\n---\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790470f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cur_problem_state)\n",
    "print(len(steps), len(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c143819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute deriving steps\n",
    "for ((step_header, step_code), next_parsed_state) in zip(deductive_steps[:-1], deductive_states[1:-1]):\n",
    "    assert len(next_parsed_state) == 1\n",
    "    next_parsed_goal = dacite.from_dict(Goal, next_parsed_state[0])\n",
    "    cur_step = ProblemGenerationStep(   # ProblemGenerationStepCategory.Derive\n",
    "        step_draft=step_header + step_code,\n",
    "        proof=[],\n",
    "        new_contexts=[]\n",
    "    )\n",
    "    \n",
    "    new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    assert len(new_problem_state.goals) == 1 and new_problem_state.goals[0].target == 'False', str(new_problem_state)\n",
    "    idents = set(cur_step.step.split())\n",
    "    for banned_token in BANNED_TOKENS:\n",
    "        if banned_token in idents:\n",
    "            logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Banned token \"{banned_token}\" in step \"{step_code}\"')\n",
    "            \n",
    "    cur_step.new_contexts = [\n",
    "        v for v in new_problem_state.goals[0].variables if\n",
    "            v.raw_name not in {vv.raw_name for vv in cur_problem_state.goals[0].variables}\n",
    "            # v not in forward_state.goals[0].variables\n",
    "    ]\n",
    "    if len(cur_step.new_contexts) == 0:\n",
    "        logger.debug(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Unused step: {str(cur_step)}')\n",
    "    \n",
    "    print(cur_step.step)\n",
    "    print('\\n')\n",
    "    print(new_problem_state)\n",
    "    print('\\n---\\n')\n",
    "    states.append(new_problem_state)\n",
    "    steps.append(cur_step)\n",
    "    cur_problem_state = new_problem_state\n",
    "\n",
    "    if next_parsed_goal.variables != cur_problem_state.goals[0].variables:\n",
    "        logger.debug(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): next_parsed_goal.variables != cur_problem_state.goals[0].variables: {[str(next_parsed_goal), str(cur_problem_state.goals[0])]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deductive_steps[-2][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2869cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute submitting step\n",
    "assert len(deductive_states[-1]) == 0\n",
    "step_code = remove_comments(deductive_steps[-1][-1]).strip()\n",
    "assert step_code.startswith('exact '), step_code\n",
    "submission_name = step_code[len('exact '):]\n",
    "\n",
    "if ' ' in submission_name or '.' in submission_name:\n",
    "    new_name = generate_submission_name([v.name for v in cur_problem_state.goals[0].variables if v.name is not None])\n",
    "    cur_step = ProblemGenerationStep(   # ProblemGenerationStepCategory.Derive\n",
    "        step_draft=f'have {new_name} : {init_parsed_goal.target} := {submission_name}',\n",
    "        proof=[],\n",
    "        new_contexts=[]\n",
    "    )\n",
    "    submission_name = new_name\n",
    "    \n",
    "    try:\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    except (TacticFailure, ServerError):\n",
    "        cur_step.step_draft = tactic_header + cur_step.step_draft\n",
    "        new_problem_state = await server.goal_tactic_async(cur_problem_state, 0, cur_step.step)\n",
    "    assert len(new_problem_state.goals) == 1 and new_problem_state.goals[0].target == 'False', str(new_problem_state)\n",
    "    idents = set(cur_step.step.split())\n",
    "    for banned_token in BANNED_TOKENS:\n",
    "        if banned_token in idents:\n",
    "            logger.critical(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Banned token \"{banned_token}\" in step \"{step_code}\"')\n",
    "    \n",
    "    cur_step.new_contexts = [\n",
    "        v for v in new_problem_state.goals[0].variables if\n",
    "            v.raw_name not in {vv.raw_name for vv in cur_problem_state.goals[0].variables}\n",
    "            # v not in forward_state.goals[0].variables\n",
    "    ]\n",
    "    if len(cur_step.new_contexts) == 0:\n",
    "        logger.warning(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): Unused step: {str(cur_step)}')\n",
    "    \n",
    "    states.append(new_problem_state)\n",
    "    steps.append(cur_step)\n",
    "    cur_problem_state = new_problem_state\n",
    "\n",
    "assert submission_name in [v.name for v in cur_problem_state.goals[0].variables], f'submission_name={submission_name}, cur_problem_state={cur_problem_state}'\n",
    "steps.append(\n",
    "    ProblemGenerationStep(   # ProblemGenerationStepCategory.Submit\n",
    "        step_draft=f'submit_answer {submission_name}',\n",
    "        proof=None,\n",
    "        new_contexts=None\n",
    "    )\n",
    ")\n",
    "\n",
    "# Parsed trajectory\n",
    "result = ProblemGenerationProcess(\n",
    "    informal_problem='',\n",
    "    informal_answer='',\n",
    "    informal_solution='',\n",
    "    header=None,\n",
    "    formal_statement='',\n",
    "    formal_solution_draft='',\n",
    "    formal_proofs='',\n",
    "    steps=steps,\n",
    "    dependencies=[],\n",
    "    trajectory=[(S.goals[0].variables, i) for i, S in enumerate(states)],\n",
    "    metainfo=dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cur_problem_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2920f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(states), len(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassemble trajectory\n",
    "is_analyzed = await agent.analyze_async(\n",
    "    result=result,\n",
    "    states=states,\n",
    "    server=server,\n",
    "    tag=str(base_cnt+idx),\n",
    "    reassemble_trajectory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da35dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metainfo = json.dumps(result.metainfo | {'time_consumption': time.time() - time_start})\n",
    "\n",
    "u['generation_process'] = result\n",
    "logger.debug(f'async_worker({base_cnt+idx}-{i_p}/{len(remaining_units)}): succeeded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bdf89",
   "metadata": {},
   "source": [
    "### Data Composition - Deductive Proof Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_lengths = []\n",
    "for d in data_parsed:\n",
    "    for u in d['parse_result']['units']:\n",
    "        if 'deductive_steps' in u.keys():\n",
    "            assert len(u['invocations'] or []) > 0\n",
    "            proof_lengths.append(len(u['deductive_steps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.Counter(proof_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# bins: Number of intervals to group integers (adjust based on your data range)\n",
    "plt.hist(proof_lengths, bins=40, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Proof Length', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_deductive_proof_generation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73df803",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = (\"\"\"\n",
    "import Mathlib\n",
    "import Aesop\n",
    "\n",
    "\"\"\" + '\\n'.join('set_option ' + t.replace('=', ' ') for t in CORE_OPTIONS)).strip()\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097dc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_parsed:\n",
    "    for u in d['parse_result']['units']:\n",
    "        if 'deductive_steps' in u.keys():\n",
    "            assert len(u['invocations'] or []) > 0\n",
    "            \n",
    "            init_state = u['deductive_states'][0]\n",
    "            assert len(init_state) == 1\n",
    "            init_state = from_dict(Goal, init_state[0])\n",
    "            \n",
    "            whole_proof = u['whole_proof']\n",
    "            if whole_proof is None:\n",
    "                # There is only one `whole_proof is None`, and is manually validated by Qi\n",
    "                whole_proof = ''\n",
    "                for t, s in u['deductive_steps']:\n",
    "                    if len(t) > 0:\n",
    "                        whole_proof += t\n",
    "                    whole_proof += s + '\\n\\n'\n",
    "                whole_proof = whole_proof.strip()\n",
    "            \n",
    "            data_deductive_proof_generation.append({\n",
    "                \"conversation\":[\n",
    "                    {\n",
    "                        \"input\": f\"\"\"\n",
    "Assume the following header is executed:\n",
    "```lean4\n",
    "{header}\n",
    "```\n",
    "\n",
    "Generate a deductive proof for the following Lean 4 proof state:\n",
    "```lean4\n",
    "{str(init_state)}\n",
    "```\n",
    "\"\"\".strip(),\n",
    "                        \"output\": f'''\n",
    "# Deductive Proof\n",
    "```lean4\n",
    "{whole_proof}\n",
    "```\n",
    "'''.strip()\n",
    "                    }\n",
    "                ]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_xtuner_sample(random.choice(data_deductive_proof_generation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/deductive_proof_generation.40069.jsonl', 'w') as f:\n",
    "    for d in data_deductive_proof_generation:\n",
    "        f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3cd93",
   "metadata": {},
   "source": [
    "### Data Composition - Autoregressive Problem Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b89846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an Olympiad problem setter and a Lean 4 expert.\n",
      "You revel in conjuring elegant problems — starting from a spare set of hypotheses, you let rigorous deduction lead you to surprising and beautiful conclusions.\n"
     ]
    }
   ],
   "source": [
    "def format_forward_solution_step_prompt(datapoint: Dict, introduced_fvars: List[str], state: List[Variable]) -> str:\n",
    "    context = ''\n",
    "    vars_to_format = [v for v in state]\n",
    "    while len(vars_to_format) > 0:\n",
    "        for i in range(len(vars_to_format)):\n",
    "            if i + 1 == len(vars_to_format) or not (vars_to_format[i].t == vars_to_format[i+1].t and vars_to_format[i].v is None and vars_to_format[i+1].v is None):\n",
    "                break\n",
    "        if i == 0:\n",
    "            context += str(vars_to_format[0]) + '\\n'\n",
    "            vars_to_format.pop(0)\n",
    "        else:\n",
    "            context += ' '.join([v.name if v.name is not None else \"_\" for v in vars_to_format[:i+1]]) + f' : {vars_to_format[0].t}\\n'\n",
    "            vars_to_format = vars_to_format[i+1:]\n",
    "    \n",
    "    introduced_fvars = '\\n'.join(introduced_fvars)\n",
    "    prompt = f'''Given the introduced variables/hypotheses and the current context in Lean 4, propose the single most natural next step to explore toward a beautiful conclusion — either\n",
    "- derive a new intermediate fact,\n",
    "- introduce a fresh variable or hypothesis, or\n",
    "- submit one of the local facts as the final answer.\n",
    "\n",
    "Requirements\n",
    "1. Flavoured \"{datapoint['problem_type']}\" and suitable for posting on forums about \"{datapoint['source']}\".\n",
    "2. Fully formal Lean 4 code (inline comments in natural language are fine for planning and reasoning). Assume `import Mathlib`.\n",
    "\n",
    "# Introduced Variables/Hypotheses\n",
    "```lean4\n",
    "{introduced_fvars}\n",
    "```\n",
    "\n",
    "# Lean 4 Context\n",
    "```lean4\n",
    "{context.rstrip()}\n",
    "```\n",
    "'''.strip()\n",
    "    return prompt\n",
    "\n",
    "def format_step(self):\n",
    "    if self.proof is None:\n",
    "        return self.step_draft  # Here do not remove comment\n",
    "    else:\n",
    "        normalized_step_draft = normalize_draft(self.step_draft)\n",
    "        matches = list(re.finditer(':= sorry', normalized_step_draft))\n",
    "        assert len(matches) == len(self.proof)\n",
    "        for (m, p) in reversed(list(zip(matches, self.proof))):\n",
    "            normalized_step_draft = replace_span(m.span(), ':= by {\\n' + '\\n'.join('  ' + l for l in p.splitlines()) + '\\n}', normalized_step_draft)\n",
    "        return normalized_step_draft\n",
    "\n",
    "def format_forward_solution_step_response(step: ProblemGenerationStep):\n",
    "    step_type = 'Derive' if step.is_deducing else 'Introduce' if step.is_introducing else 'Submit'\n",
    "    response = f'''# Step {step_type}\n",
    "```lean4\n",
    "{format_step(step).rstrip()}\n",
    "```\n",
    "'''.strip()\n",
    "    return response\n",
    "\n",
    "print(SYSTEM_PROMPT_FPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8be6f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41543 40069 39980 39509\n"
     ]
    }
   ],
   "source": [
    "n_total_units = 0\n",
    "n_transformed_units = 0\n",
    "n_deductive_units = 0\n",
    "n_reassembled_units = 0\n",
    "\n",
    "transformed_units = []\n",
    "\n",
    "for d in data_parsed:\n",
    "    units = d['parse_result']['units']\n",
    "    all_parsed_units = [i_u for i_u, u in enumerate(units) if len(u['invocations'] or []) > 0]\n",
    "    transformed_units.extend([(d, units[i_u]) for i_u in all_parsed_units if 'deductive_steps' in units[i_u].keys()])\n",
    "\n",
    "    n_total_units += len(all_parsed_units)\n",
    "\n",
    "deductive_units = [(d, u) for (d, u) in transformed_units if 'generation_process' in u.keys()] # Successfully execited w/ `False` target\n",
    "reassembled_units = [(d, u) for (d, u) in deductive_units if 'original_trajectory' in u['generation_process'].metainfo] # Successfully execited w/ `False` target\n",
    "    \n",
    "\n",
    "print(n_total_units, len(transformed_units), len(deductive_units), len(reassembled_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f6bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    dict(problem_type=d['problem_type'], source=d['source']) for (d, u) in reassembled_units\n",
    "]\n",
    "with open('/home/ma-user/workspace/formal_problem_generation/formal_problem_generation/data/conditions.numina_lean.39509.json', 'w') as f:\n",
    "    json.dump(conditions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.Counter([d['problem_type'] for (d, u) in reassembled_units]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d538295",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.Counter([d['source'] for (d, u) in reassembled_units]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_problem_generation = []\n",
    "\n",
    "for (d, u) in reassembled_units:\n",
    "    result: ProblemGenerationProcess = u['generation_process']\n",
    "    steps = result.steps\n",
    "\n",
    "    introduced_fvars = []\n",
    "    data_problem_generation_chunk = []\n",
    "    is_success = True\n",
    "    \n",
    "    for i, (context_fvars, step_id) in enumerate(result.trajectory):\n",
    "        step: ProblemGenerationStep = steps[step_id]\n",
    "        step.step_draft = step.step_draft.replace(' :  ', ' : ')\n",
    "        \n",
    "        if step.is_deducing:\n",
    "            idents = set(step.step.split())\n",
    "            for banned_token in BANNED_TOKENS:\n",
    "                if banned_token in idents:\n",
    "                    if any(v.name == banned_token for v in context_fvars):\n",
    "                        logger.warning(f'Banned token \"{banned_token}\" in step \"{step.step}\", but is also in context.')\n",
    "                    else:\n",
    "                        logger.error(f'Banned token \"{banned_token}\" in step \"{step.step}\"')\n",
    "                        is_success = False\n",
    "                        break\n",
    "        else:\n",
    "            idents = set(step.step.split())\n",
    "            for banned_token in BANNED_TOKENS[1:]:\n",
    "                if banned_token in idents:\n",
    "                    if any(v.name == banned_token for v in context_fvars):\n",
    "                        logger.warning(f'Banned token \"{banned_token}\" in step \"{step.step}\", but is also in context.')\n",
    "                    else:\n",
    "                        logger.error(f'Banned token \"{banned_token}\" in step \"{step.step}\"')\n",
    "                        is_success = False\n",
    "                        break\n",
    "        \n",
    "        data_problem_generation_chunk.append({\n",
    "            \"conversation\":[\n",
    "                {\n",
    "                    \"system\": SYSTEM_PROMPT_FPG,\n",
    "                    \"input\": format_forward_solution_step_prompt(d, introduced_fvars, context_fvars),\n",
    "                    \"output\": format_forward_solution_step_response(step)\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        if step.is_introducing:\n",
    "            lines = step.step_draft.splitlines()\n",
    "            while len(lines) > 0 and lines[0].split()[0] in ['open', 'set_option']:\n",
    "                lines.pop(0)\n",
    "            step_code = '\\n'.join(lines)\n",
    "            assert step_code.startswith('have ') and step_code.endswith(' := sorry')\n",
    "            introduced_fvars.append(step_code[len('have '):-len(' := sorry')].strip())\n",
    "\n",
    "        if step.is_submitting:\n",
    "            assert i == len(result.trajectory) - 1\n",
    "    \n",
    "    if is_success:\n",
    "        data_problem_generation.extend(data_problem_generation_chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in data_problem_generation_chunk:\n",
    "    print_xtuner_sample(s)\n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a483b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_problem_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/problem_generation_steps.reasseblmed.39509.jsonl', 'w') as f:\n",
    "    for s in data_problem_generation:\n",
    "        f.write(json.dumps(s) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b30e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (d, u) in reassembled_units:\n",
    "    result: ProblemGenerationProcess = u['generation_process']\n",
    "    \n",
    "    if isinstance(u['generation_process'].metainfo, str):\n",
    "        u['generation_process'].metainfo = json.loads(u['generation_process'].metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf08d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.Counter(\n",
    "    u['generation_process'].trajectory == [\n",
    "        ([dacite.from_dict(Variable, v) for v in S], s) for (S, s) in u['generation_process'].metainfo['original_trajectory']\n",
    "    ] for (d, u) in reassembled_units\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649f81b",
   "metadata": {},
   "source": [
    "### Data Composition - Whole-Statement Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assume the following header is executed:\n",
    "```lean4\n",
    "{header}\n",
    "```\n",
    "\n",
    "Generate a deductive proof for the following Lean 4 proof state:\n",
    "```lean4\n",
    "{str(init_state)}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_whole_statement_generation_prompt(datapoint: Dict) -> str:\n",
    "    prompt = f'''Propose a Lean 4 statement that explores toward a beautiful conclusion.\n",
    "\n",
    "Requirements\n",
    "1. Flavoured {datapoint['problem_type']} and suitable for posting on forums about {datapoint['source']}.\n",
    "2. Fully formal Lean 4 code (inline comments in natural language are fine for planning and reasoning). Assume `import Mathlib`.\n",
    "'''.strip()\n",
    "    return prompt\n",
    "\n",
    "def format_statement(load_header, formal_statement):\n",
    "    formal_code = ((load_header + '\\n') if len(load_header) > 0 else '') + formal_statement\n",
    "    return f'''# Statement\n",
    "```lean4\n",
    "{formal_code.strip()}\n",
    "```\n",
    "'''.strip()\n",
    "\n",
    "print(SYSTEM_PROMPT_FPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reassembled_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whole_statement_generation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a241b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (d, u) in reassembled_units:\n",
    "    formal_statement = u['formal_statement']\n",
    "    load_header = u['load_header']\n",
    "    variables = []\n",
    "    if formal_statement.startswith('∀ '):\n",
    "        context, target = parse_variables(formal_statement[len('∀ '):])\n",
    "    else:\n",
    "        target = formal_statement.strip()\n",
    "    \n",
    "    new_formal_statement = 'example\\n' + (('\\n'.join(context) + '\\n') if len(context) > 0 else '') + ': ' + target + '\\n:= sorry'\n",
    "    \n",
    "    data_whole_statement_generation.append({\n",
    "        \"conversation\":[\n",
    "            {\n",
    "                \"system\": SYSTEM_PROMPT_FPG,\n",
    "                \"input\": format_whole_statement_generation_prompt(d),\n",
    "                \"output\": format_statement(load_header, new_formal_statement)\n",
    "            }\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_xtuner_sample(random.choice(data_whole_statement_generation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/whole_statement_generation.39576.jsonl', 'w') as f:\n",
    "    for s in data_whole_statement_generation:\n",
    "        f.write(json.dumps(s) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5baf9",
   "metadata": {},
   "source": [
    "## Informalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7615cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/add_2_key_proof_solution_sft_mixed.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ma-user/workspace/formal_problem_generation/data/Numina-Lean/add_2_key_proof_solution_sft_mixed_str_alpaca.json', 'r') as f:\n",
    "    data_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771afbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_informalization_prompt(formal_statement: str, formal_proof: str) -> str:\n",
    "    formal_statement = replace_sorry(formal_statement)\n",
    "    assert formal_statement.endswith(':= sorry')\n",
    "    formal_code = formal_statement[:-len('sorry')] + 'by\\n' + formal_proof\n",
    "    return f'''Given a Lean 4 formal statement and its proof, please translate them into natural language.\n",
    "**Requirements**:\n",
    "1. Determine its question type: \"Problem-Solving Question\" or \"Proof Question\".\n",
    "2. Convert the formal statement into an informal question, and convert the formal proof into informal solution steps.\n",
    "3. If it is a problem-solving question, please also output its answer.\n",
    "\n",
    "```lean4\n",
    "{formal_code}\n",
    "```\n",
    "'''\n",
    "\n",
    "PTYPE_DICT = {\n",
    "    'solution problem': 'Problem-Solving Question',\n",
    "    'proof problem': 'Proof Question'\n",
    "} \n",
    "\n",
    "def format_informalization_response(\n",
    "    problem_type: str,\n",
    "    informal_problem: str,\n",
    "    informal_solution: str,\n",
    "    informal_answer: Optional[str]\n",
    ") -> str:\n",
    "    assert all(split not in field\n",
    "        for split in [f'# Problem-Solving Question', '# Proof Question', '# Answer', '# Solution']\n",
    "        for field in [problem_type, informal_problem, informal_solution, informal_answer]\n",
    "    )\n",
    "    response = f'# {PTYPE_DICT[problem_type.strip()]}\\n{informal_problem.strip()}\\n'\n",
    "    if problem_type == 'solution problem':\n",
    "        assert informal_answer is not None\n",
    "        response += f'# Answer\\n{informal_answer.strip()}\\n'\n",
    "    response += f'# Solution\\n{informal_solution.strip()}\\n'\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.constants import SYSTEM_PROMPT_SFT\n",
    "data_train_xtuner = []\n",
    "data_failed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a4693",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_train:\n",
    "    d_in = json.loads(d['input'])\n",
    "    assert d_in.keys() == {'formal_problem', 'formal_solution'}\n",
    "    d_out = json.loads(d['output'])\n",
    "    assert d_out.keys() == {'problem_type', 'informal_problem', 'informal_solution', 'informal_answer'}\n",
    "\n",
    "    try:\n",
    "        data_train_xtuner.append({\n",
    "            \"conversation\":[\n",
    "                {\n",
    "                    \"system\": SYSTEM_PROMPT_SFT,\n",
    "                    \"input\": format_informalization_prompt(formal_statement=d_in['formal_problem'], formal_proof=d_in['formal_solution']),\n",
    "                    \"output\": format_informalization_response(**d_out)\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "    except:\n",
    "        data_failed.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_failed), len(data_train_xtuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_xtuner_sample(data: list):\n",
    "    if 'system' in data['conversation'][0].keys():\n",
    "        print('<SYSTEM>')\n",
    "        print(data['conversation'][0]['system'])\n",
    "        print('</SYSTEM>')\n",
    "    print('<INPUT>')\n",
    "    print(data['conversation'][0]['input'])\n",
    "    print('</INPUT>\\n<OUTPUT>')\n",
    "    print(data['conversation'][0]['output'])\n",
    "    print('</OUTPUT>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_xtuner_sample(random.choice(data_train_xtuner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5760d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/sfs/liuqi/data/Numina-Lean/data_informalization_train.jsonl', 'w') as f:\n",
    "    for d in data_train_xtuner:\n",
    "        f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out['problem_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e022e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out['informal_problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8735457",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out['informal_solution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out['informal_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f706e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d333b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f57c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
