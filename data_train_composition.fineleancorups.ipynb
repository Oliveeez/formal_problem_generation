{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401386e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/nnae/latest owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/nnae/8.2.RC1/ascend_nnae_install.info owner does not match the current owner.\n",
      "  warnings.warn(f\"Warning: The {path} owner does not match the current owner.\")\n",
      "/home/ma-user/anaconda3/envs/default/lib/python3.11/site-packages/torch_npu/__init__.py:289: UserWarning: On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default.                      Do not set it to 1 to prevent some unknown errors\n",
      "  warnings.warn(\"On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default. \\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import pickle\n",
    "import collections as C\n",
    "import itertools as I\n",
    "import random\n",
    "import regex as re\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "import time\n",
    "\n",
    "import msgspec\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from dacite import from_dict\n",
    "import dacite\n",
    "\n",
    "from common.constants import SYSTEM_PROMPT_FPG, CORE_OPTIONS, BANNED_TOKENS\n",
    "from common.utils import remove_comments, replace_sorry, replace_calc, remove_multiline_comments, remove_singleline_comments, parse_idents, normalize_spaces\n",
    "from common.pantograph.dataclasses import ProblemGenerationProcess, ProblemGenerationStep, Variable, normalize_draft, replace_span, Goal, GoalState, ProblemGenerationStep, ProblemGenerationProcess, TacticDraft\n",
    "from common.pantograph.server import PersistentServer, TacticFailure, ServerError\n",
    "from agent.problem_generation import AutoregressiveProblemGenerationAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ff4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dones_root = '/home/ma-user/workspace/formal_problem_generation/data/FineLeanCorpus/dones'\n",
    "dones_different_root = '/home/ma-user/workspace/formal_problem_generation/data/FineLeanCorpus/different_dones_32672'\n",
    "n_chunks = 498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65caf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 291/498 [00:28<00:10, 19.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(297984): diff_cnt=1\n",
      "Chunk(299008): diff_cnt=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 294/498 [00:28<00:14, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(300032): diff_cnt=0\n",
      "Chunk(301056): diff_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 296/498 [00:29<00:16, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(302080): diff_cnt=0\n",
      "Chunk(303104): diff_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 298/498 [00:32<01:30,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(304128): diff_cnt=3\n",
      "Chunk(305152): diff_cnt=0\n",
      "Chunk(306176): diff_cnt=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 302/498 [00:32<00:57,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(307200): diff_cnt=2\n",
      "Chunk(308224): diff_cnt=0\n",
      "Chunk(309248): diff_cnt=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 304/498 [00:33<00:47,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(310272): diff_cnt=2\n",
      "Chunk(311296): diff_cnt=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 307/498 [00:33<00:37,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(312320): diff_cnt=1\n",
      "Chunk(313344): diff_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 309/498 [00:33<00:31,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(314368): diff_cnt=1\n",
      "Chunk(315392): diff_cnt=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 311/498 [00:33<00:27,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(316416): diff_cnt=2\n",
      "Chunk(317440): diff_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 313/498 [00:34<00:25,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(318464): diff_cnt=1\n",
      "Chunk(319488): diff_cnt=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 315/498 [00:34<00:22,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(320512): diff_cnt=0\n",
      "Chunk(321536): diff_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 317/498 [00:34<00:21,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(322560): diff_cnt=1\n",
      "Chunk(323584): diff_cnt=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 319/498 [00:34<00:21,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(324608): diff_cnt=0\n",
      "Chunk(325632): diff_cnt=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 320/498 [00:35<00:21,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(326656): diff_cnt=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 322/498 [00:38<02:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(327680): diff_cnt=1\n",
      "Chunk(328704): diff_cnt=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 324/498 [00:38<01:19,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(329728): diff_cnt=2\n",
      "Chunk(330752): diff_cnt=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 326/498 [00:38<00:48,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(331776): diff_cnt=0\n",
      "Chunk(332800): diff_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 328/498 [00:39<00:32,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(333824): diff_cnt=0\n",
      "Chunk(334848): diff_cnt=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 330/498 [00:39<00:26,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk(335872): diff_cnt=0\n",
      "Chunk(336896): diff_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [01:00<00:00,  8.28it/s]\n"
     ]
    }
   ],
   "source": [
    "data_main = []\n",
    "data_extra = []\n",
    "\n",
    "for i_chunk in tqdm(list(range(n_chunks))):\n",
    "    with open(osp.join(dones_root, f'done_chunk_{1024 * i_chunk}.pkl'), 'rb') as f:\n",
    "        chunk = pickle.load(f)\n",
    "    with open(osp.join(dones_root, f'reassembled_fixed_chunk_{1024 * i_chunk}.pkl'), 'rb') as f:\n",
    "        chunk_fixed = pickle.load(f)\n",
    "    assert len(chunk) == len(chunk_fixed)\n",
    "    for (i, c) in enumerate(chunk_fixed):\n",
    "        if c is not None:\n",
    "            assert chunk[i].informal_problem == c.informal_problem\n",
    "            chunk[i] = c\n",
    "    \n",
    "    if osp.exists(osp.join(dones_different_root, f'reassembled_fixed_chunk_{1024 * i_chunk}.pkl')):\n",
    "        with open(osp.join(dones_different_root, f'done_chunk_{1024 * i_chunk}.pkl'), 'rb') as f:\n",
    "            chunk_extra = pickle.load(f)\n",
    "        with open(osp.join(dones_different_root, f'reassembled_fixed_chunk_{1024 * i_chunk}.pkl'), 'rb') as f:\n",
    "            chunk_fixed = pickle.load(f)\n",
    "        assert len(chunk_extra) == len(chunk_fixed)\n",
    "        for (i, c) in enumerate(chunk_fixed):\n",
    "            if c is not None:\n",
    "                assert chunk_extra[i].informal_problem == c.informal_problem\n",
    "                chunk_extra[i] = c\n",
    "        \n",
    "        diff_cnt = 0\n",
    "        for i, (d1, d2) in enumerate(zip(chunk, chunk_extra)):\n",
    "            # if d1 is None:\n",
    "            #     data_reassembled.append(d2)\n",
    "            # elif d2 is None:\n",
    "            #     data_reassembled.append(d1)\n",
    "            # else:\n",
    "            assert d1.informal_problem == d2.informal_problem\n",
    "            meta1 = d1.metainfo if isinstance(d1.metainfo, dict) else json.loads(d1.metainfo)\n",
    "            meta2 = d2.metainfo if isinstance(d2.metainfo, dict) else json.loads(d2.metainfo)\n",
    "            assert meta1['id'] == meta2['id']\n",
    "            \n",
    "            # Whether falsified\n",
    "            if 'falsified_model' in meta1.keys():\n",
    "                continue\n",
    "            elif 'falsified_model' in meta2.keys():\n",
    "                diff_cnt += 1\n",
    "                chunk[i] = d2\n",
    "            else:\n",
    "                # Whether reassembled\n",
    "                if 'original_trajectory' in meta1.keys():\n",
    "                    continue\n",
    "                elif 'original_trajectory' in meta2.keys():\n",
    "                    diff_cnt += 1\n",
    "                    chunk[i] = d2\n",
    "                else:\n",
    "                    # Whether decomposed\n",
    "                    if len(d1.trajectory) > 0:\n",
    "                        continue\n",
    "                    elif len(d2.trajectory) > 0:\n",
    "                        diff_cnt += 1\n",
    "                        chunk[i] = d2\n",
    "                    else:\n",
    "                        if 'proven_model' in meta1.keys():\n",
    "                            continue\n",
    "                        elif 'proven_model' in meta2.keys():\n",
    "                            diff_cnt += 1\n",
    "                            chunk[i] = d2\n",
    "                        else:\n",
    "                            pass\n",
    "        print(f'Chunk({i_chunk * 1024}): diff_cnt={diff_cnt}')\n",
    "    data_main.extend(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88faac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_falsified = []\n",
    "data_reassembled = []\n",
    "data_decomposed = []\n",
    "data_proven = []\n",
    "data_failed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168d723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d1 in data_main:\n",
    "    if isinstance(d1.metainfo, str):\n",
    "        d1.metainfo = json.loads(d1.metainfo)\n",
    "    meta1 = d1.metainfo\n",
    "    \n",
    "    # Whether falsified\n",
    "    if 'falsified_model' in meta1.keys():\n",
    "        data_falsified.append(d1)\n",
    "    else:\n",
    "        # Whether reassembled\n",
    "        if 'original_trajectory' in meta1.keys():\n",
    "            data_reassembled.append(d1)\n",
    "        else:\n",
    "            # Whether decomposed\n",
    "            if len(d1.trajectory) > 0:\n",
    "                data_decomposed.append(d1)\n",
    "            else:\n",
    "                if 'proven_model' in meta1.keys():\n",
    "                    data_proven.append(d1)\n",
    "                else:\n",
    "                    data_failed.append(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d33736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2614, 82438, 349, 11375, 412582)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_falsified), len(data_reassembled), len(data_decomposed), len(data_proven), len(data_failed), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63fcf937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 51187, False: 31251})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.Counter(\n",
    "    d.trajectory == [\n",
    "        ([dacite.from_dict(Variable, v) for v in S], s) for (S, s) in d.metainfo['original_trajectory']\n",
    "    ] for d in data_reassembled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726d1130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 18512,\n",
       "         4: 12370,\n",
       "         3: 9425,\n",
       "         6: 8156,\n",
       "         8: 6274,\n",
       "         5: 5253,\n",
       "         10: 4112,\n",
       "         7: 3650,\n",
       "         11: 3275,\n",
       "         9: 3220,\n",
       "         12: 2586,\n",
       "         14: 1403,\n",
       "         13: 1346,\n",
       "         15: 819,\n",
       "         16: 604,\n",
       "         17: 389,\n",
       "         18: 283,\n",
       "         19: 216,\n",
       "         20: 146,\n",
       "         21: 107,\n",
       "         22: 81,\n",
       "         23: 51,\n",
       "         24: 35,\n",
       "         26: 23,\n",
       "         25: 19,\n",
       "         27: 17,\n",
       "         28: 11,\n",
       "         31: 11,\n",
       "         30: 10,\n",
       "         29: 8,\n",
       "         33: 5,\n",
       "         38: 3,\n",
       "         32: 3,\n",
       "         35: 2,\n",
       "         54: 2,\n",
       "         57: 2,\n",
       "         43: 1,\n",
       "         53: 1,\n",
       "         61: 1,\n",
       "         36: 1,\n",
       "         105: 1,\n",
       "         39: 1,\n",
       "         42: 1,\n",
       "         110: 1,\n",
       "         34: 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.Counter(len(d.trajectory) for d in data_reassembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05c9ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509358\n"
     ]
    }
   ],
   "source": [
    "with open(osp.join('/home/ma-user/local_cache/m-a-p/FineLeanCorpus', 'FineLeanCorpus_v2.jsonl'), 'r') as f:\n",
    "    data_informal = [json.loads(l) for l in f.readlines()]\n",
    "print(len(data_informal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b69c5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_informal[0].keys()\n",
    "d = data_informal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70763488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509358\n"
     ]
    }
   ],
   "source": [
    "id_to_idx = {i : d['id'] for (i, d) in enumerate(data_informal)}\n",
    "print(len(id_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "207ccf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Algebra -> Intermediate Algebra -> Functional Equations'],\n",
       " 1,\n",
       " 'AoPs',\n",
       " 'The problem involves finding the value of a constant in a linear relationship between two variables and then using it to find the value of one variable given the other.',\n",
       " 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['domain'], d['difficulty'], d['source'], d['domain_summary'], d['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89c73102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'AoPs': 350714,\n",
       "         'DeepMath-103k': 45853,\n",
       "         'NuminaMath-TIR': 45152,\n",
       "         'DeepTheorem': 31409,\n",
       "         'DeepScaleR': 22360,\n",
       "         'DAPO-Math-17k': 8868,\n",
       "         'Omni-MATH': 1181,\n",
       "         'IneqMath': 1180,\n",
       "         'BlueMO': 1099,\n",
       "         'Multi-Source_Math_Competition': 993,\n",
       "         'TAL-SCQ5K': 393,\n",
       "         'OnlineMathContest': 156})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.Counter(\n",
    "    d['source'] for d in data_informal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e574e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an Olympiad problem setter and a Lean 4 expert.\n",
      "You revel in conjuring elegant problems — starting from a spare set of hypotheses, you let rigorous deduction lead you to surprising and beautiful conclusions.\n"
     ]
    }
   ],
   "source": [
    "def format_forward_solution_step_prompt(idx: int, introduced_fvars: List[str], state: List[Variable]) -> str:\n",
    "    d = data_informal[id_to_idx[idx]]\n",
    "    context = ''\n",
    "    vars_to_format = [v for v in state]\n",
    "    while len(vars_to_format) > 0:\n",
    "        for i in range(len(vars_to_format)):\n",
    "            if i + 1 == len(vars_to_format) or not (vars_to_format[i].t == vars_to_format[i+1].t and vars_to_format[i].v is None and vars_to_format[i+1].v is None):\n",
    "                break\n",
    "        if i == 0:\n",
    "            context += str(vars_to_format[0]) + '\\n'\n",
    "            vars_to_format.pop(0)\n",
    "        else:\n",
    "            context += ' '.join([v.name if v.name is not None else \"_\" for v in vars_to_format[:i+1]]) + f' : {vars_to_format[0].t}\\n'\n",
    "            vars_to_format = vars_to_format[i+1:]\n",
    "    \n",
    "    introduced_fvars = '\\n'.join(introduced_fvars)\n",
    "    prompt = f'''Given the introduced variables/hypotheses and the current context in Lean 4, propose the single most natural next step to explore toward a beautiful conclusion — either\n",
    "- derive a new intermediate fact,\n",
    "- introduce a fresh variable or hypothesis, or\n",
    "- submit one of the local facts as the final answer.\n",
    "\n",
    "Requirements\n",
    "1. Flavoured {d['domain']} and of difficulty level {d['difficulty']}.\n",
    "2. Fully formal Lean 4 code (inline comments in natural language are fine for planning and reasoning). Assume `import Mathlib`.\n",
    "\n",
    "# Introduced Variables/Hypotheses\n",
    "```lean4\n",
    "{introduced_fvars}\n",
    "```\n",
    "\n",
    "# Lean 4 Context\n",
    "```lean4\n",
    "{context.rstrip()}\n",
    "```\n",
    "'''.strip()\n",
    "    return prompt\n",
    "\n",
    "def format_step(self):\n",
    "    if self.proof is None:\n",
    "        return self.step_draft  # Here do not remove comment\n",
    "    else:\n",
    "        normalized_step_draft = normalize_draft(self.step_draft)\n",
    "        matches = list(re.finditer(':= sorry', normalized_step_draft))\n",
    "        assert len(matches) == len(self.proof)\n",
    "        for (m, p) in reversed(list(zip(matches, self.proof))):\n",
    "            normalized_step_draft = replace_span(m.span(), ':= by {\\n' + '\\n'.join('  ' + l for l in p.splitlines()) + '\\n}', normalized_step_draft)\n",
    "        return normalized_step_draft\n",
    "\n",
    "def format_forward_solution_step_response(step: ProblemGenerationStep):\n",
    "    step_type = 'Derive' if step.is_deducing else 'Introduce' if step.is_introducing else 'Submit'\n",
    "    response = f'''# Step {step_type}\n",
    "```lean4\n",
    "{format_step(step).rstrip()}\n",
    "```\n",
    "'''.strip()\n",
    "    return response\n",
    "\n",
    "print(SYSTEM_PROMPT_FPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a15794aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_problem_generation = []\n",
    "\n",
    "for result in data_reassembled:\n",
    "    result: ProblemGenerationProcess\n",
    "    steps = result.steps\n",
    "\n",
    "    introduced_fvars = []\n",
    "    data_problem_generation_chunk = []\n",
    "    is_success = True\n",
    "    \n",
    "    for i, (context_fvars, step_id) in enumerate(result.trajectory):\n",
    "        step: ProblemGenerationStep = steps[step_id]\n",
    "        step.step_draft = step.step_draft.replace(' :  ', ' : ')\n",
    "        \n",
    "        if step.is_deducing:\n",
    "            idents = set(step.step.split())\n",
    "            for banned_token in BANNED_TOKENS:\n",
    "                if banned_token in idents:\n",
    "                    if any(v.name == banned_token for v in context_fvars):\n",
    "                        logger.warning(f'Banned token \"{banned_token}\" in step \"{step.step}\", but is also in context.')\n",
    "                    else:\n",
    "                        logger.error(f'Banned token \"{banned_token}\" in step \"{step.step}\"')\n",
    "                        is_success = False\n",
    "                        break\n",
    "        else:\n",
    "            idents = set(step.step.split())\n",
    "            for banned_token in BANNED_TOKENS[1:]:\n",
    "                if banned_token in idents:\n",
    "                    if any(v.name == banned_token for v in context_fvars):\n",
    "                        logger.warning(f'Banned token \"{banned_token}\" in step \"{step.step}\", but is also in context.')\n",
    "                    else:\n",
    "                        logger.error(f'Banned token \"{banned_token}\" in step \"{step.step}\"')\n",
    "                        is_success = False\n",
    "                        break\n",
    "        \n",
    "        data_problem_generation_chunk.append({\n",
    "            \"conversation\":[\n",
    "                {\n",
    "                    \"system\": SYSTEM_PROMPT_FPG,\n",
    "                    \"input\": format_forward_solution_step_prompt(result.metainfo['id'], introduced_fvars, context_fvars),\n",
    "                    \"output\": format_forward_solution_step_response(step)\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        if step.is_introducing:\n",
    "            lines = step.step_draft.splitlines()\n",
    "            while len(lines) > 0 and lines[0].split()[0] in ['open', 'set_option']:\n",
    "                lines.pop(0)\n",
    "            step_code = '\\n'.join(lines)\n",
    "            assert step_code.startswith('have ') and step_code.endswith(' := sorry')\n",
    "            introduced_fvars.append(step_code[len('have '):-len(' := sorry')].strip())\n",
    "\n",
    "        if step.is_submitting:\n",
    "            assert i == len(result.trajectory) - 1\n",
    "    \n",
    "    if is_success:\n",
    "        data_problem_generation.extend(data_problem_generation_chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "456e16b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490644"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_problem_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d397024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_xtuner_sample(data: list):\n",
    "    if 'system' in data['conversation'][0].keys():\n",
    "        print('<SYSTEM>')\n",
    "        print(data['conversation'][0]['system'])\n",
    "        print('</SYSTEM>')\n",
    "    print('<INPUT>')\n",
    "    print(data['conversation'][0]['input'])\n",
    "    print('</INPUT>\\n<OUTPUT>')\n",
    "    print(data['conversation'][0]['output'])\n",
    "    print('</OUTPUT>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "394758c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SYSTEM>\n",
      "You are an Olympiad problem setter and a Lean 4 expert.\n",
      "You revel in conjuring elegant problems — starting from a spare set of hypotheses, you let rigorous deduction lead you to surprising and beautiful conclusions.\n",
      "</SYSTEM>\n",
      "<INPUT>\n",
      "Given the introduced variables/hypotheses and the current context in Lean 4, propose the single most natural next step to explore toward a beautiful conclusion — either\n",
      "- derive a new intermediate fact,\n",
      "- introduce a fresh variable or hypothesis, or\n",
      "- submit one of the local facts as the final answer.\n",
      "\n",
      "Requirements\n",
      "1. Flavoured ['Algebra -> Intermediate Algebra -> Other', 'Applied Mathematics -> Other -> Other'] and of difficulty level 1.\n",
      "2. Fully formal Lean 4 code (inline comments in natural language are fine for planning and reasoning). Assume `import Mathlib`.\n",
      "\n",
      "# Introduced Variables/Hypotheses\n",
      "```lean4\n",
      "\n",
      "```\n",
      "\n",
      "# Lean 4 Context\n",
      "```lean4\n",
      "\n",
      "```\n",
      "</INPUT>\n",
      "<OUTPUT>\n",
      "# Step Derive\n",
      "```lean4\n",
      "open Real in\n",
      "have h1 : sqrt (6 * sqrt (2 * sqrt 3)) > sqrt (3 * sqrt (6 * sqrt 2)) :=\n",
      "  by\n",
      "  apply Real.sqrt_lt_sqrt\n",
      "  · positivity\n",
      "  · have h2 : sqrt (2 * sqrt 3) > sqrt (6 * sqrt 2) / 2 :=\n",
      "      by\n",
      "      have h3 : (sqrt (2 * sqrt 3)) ^ 2 > (sqrt (6 * sqrt 2) / 2) ^ 2 :=\n",
      "        by\n",
      "        have h4 : (sqrt (2 * sqrt 3)) ^ 2 = 2 * sqrt 3 := by\n",
      "          rw [Real.sq_sqrt]\n",
      "          positivity\n",
      "        have h5 : (sqrt (6 * sqrt 2) / 2) ^ 2 = (sqrt (6 * sqrt 2)) ^ 2 / 4 := by ring\n",
      "        have h6 : (sqrt (6 * sqrt 2)) ^ 2 = 6 * sqrt 2 := by\n",
      "          rw [Real.sq_sqrt]\n",
      "          positivity\n",
      "        rw [h4, h5, h6]\n",
      "        nlinarith [Real.sqrt_nonneg 3, Real.sqrt_nonneg 2, Real.sq_sqrt (show (0 : ℝ) ≤ (3 : ℝ) by norm_num),\n",
      "          Real.sq_sqrt (show (0 : ℝ) ≤ (2 : ℝ) by norm_num), sq_nonneg (sqrt 3 - sqrt 2)]\n",
      "      have h7 : sqrt (2 * sqrt 3) ≥ 0 := by positivity\n",
      "      have h8 : sqrt (6 * sqrt 2) / 2 ≥ 0 := by positivity\n",
      "      nlinarith [Real.sqrt_nonneg (2 * sqrt 3), Real.sqrt_nonneg (6 * sqrt 2)]\n",
      "    have h3 : 6 * sqrt (2 * sqrt 3) > 3 * sqrt (6 * sqrt 2) :=\n",
      "      by\n",
      "      have h4 : sqrt (2 * sqrt 3) > sqrt (6 * sqrt 2) / 2 := h2\n",
      "      nlinarith [Real.sqrt_nonneg (2 * sqrt 3), Real.sqrt_nonneg (6 * sqrt 2)]\n",
      "    linarith [h3]\n",
      "```\n",
      "</OUTPUT>\n"
     ]
    }
   ],
   "source": [
    "print_xtuner_sample(data_problem_generation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "110bc8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ma-user/workspace/formal_problem_generation/data/FineLeanCorpus/problem_generation_steps.reasseblmed.82438.jsonl', 'w') as f:\n",
    "    for s in data_problem_generation:\n",
    "        f.write(json.dumps(s) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a72426",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
